"""
ì´ìƒ íƒì§€ ëª¨ë¸ (Isolation Forest)
ë°°ì°¨ ë° ì°¨ëŸ‰ ë°ì´í„°ì—ì„œ ì´ìƒ íŒ¨í„´ íƒì§€
"""
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import joblib
import logging
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)


class AnomalyDetector:
    """ì´ìƒ íƒì§€ ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, contamination: float = 0.1, random_state: int = 42):
        """
        ì´ˆê¸°í™”
        
        Args:
            contamination: ì´ìƒì¹˜ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1 = 10%)
            random_state: ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
        """
        self.model = IsolationForest(
            contamination=contamination,
            random_state=random_state,
            n_estimators=100,
            max_samples='auto',
            n_jobs=-1
        )
        self.scaler = StandardScaler()
        self.feature_names = None
        self.is_trained = False
    
    def prepare_dispatch_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ë°°ì°¨ ë°ì´í„° íŠ¹ì§• ì¤€ë¹„
        
        Args:
            df: ë°°ì°¨ ì´ë ¥ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            pd.DataFrame: íŠ¹ì§• ë°ì´í„°í”„ë ˆì„
        """
        features_df = df.copy()
        
        # ì‹œê°„ íŠ¹ì§•
        features_df['dispatch_date'] = pd.to_datetime(features_df['dispatch_date'])
        features_df['day_of_week'] = features_df['dispatch_date'].dt.dayofweek
        features_df['hour'] = features_df['dispatch_date'].dt.hour
        features_df['is_weekend'] = (features_df['day_of_week'] >= 5).astype(int)
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì§• ì„ íƒ
        numeric_features = [
            'total_distance_km',
            'total_duration_minutes',
            'max_pallets',
            'max_weight_kg',
            'max_volume_cbm',
            'day_of_week',
            'hour',
            'is_weekend'
        ]
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_features = [f for f in numeric_features if f in features_df.columns]
        
        result_df = features_df[available_features].copy()
        
        # íŒŒìƒ íŠ¹ì§• ì¶”ê°€
        if 'total_distance_km' in result_df.columns and 'total_duration_minutes' in result_df.columns:
            # í‰ê·  ì†ë„ (km/h)
            result_df['avg_speed_kmh'] = np.where(
                result_df['total_duration_minutes'] > 0,
                (result_df['total_distance_km'] / result_df['total_duration_minutes']) * 60,
                0
            )
        
        if 'total_distance_km' in result_df.columns and 'max_volume_cbm' in result_df.columns:
            # ê±°ë¦¬ ë‹¹ ìš©ì  (kmë‹¹ CBM)
            result_df['distance_per_volume'] = np.where(
                result_df['max_volume_cbm'] > 0,
                result_df['total_distance_km'] / result_df['max_volume_cbm'],
                0
            )
        
        # NaN ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
        result_df = result_df.fillna(0)
        
        # ë¬´í•œëŒ€ ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
        result_df = result_df.replace([np.inf, -np.inf], 0)
        
        logger.info(f"âœ… ë°°ì°¨ íŠ¹ì§• ì¤€ë¹„ ì™„ë£Œ: {len(result_df)} í–‰, {len(result_df.columns)} íŠ¹ì§•")
        return result_df
    
    def prepare_vehicle_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì°¨ëŸ‰ GPS ë°ì´í„° íŠ¹ì§• ì¤€ë¹„
        
        Args:
            df: GPS ë¡œê·¸ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            pd.DataFrame: íŠ¹ì§• ë°ì´í„°í”„ë ˆì„
        """
        features_df = df.copy()
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì§•
        numeric_features = [
            'speed_kmh',
            'temperature_celsius',
            'battery_voltage'
        ]
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_features = [f for f in numeric_features if f in features_df.columns]
        
        result_df = features_df[available_features].copy()
        
        # ignition_on ë³€í™˜ (boolean -> int)
        if 'ignition_on' in features_df.columns:
            result_df['ignition_on'] = features_df['ignition_on'].astype(int)
        
        # NaN ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
        result_df = result_df.fillna(0)
        
        logger.info(f"âœ… ì°¨ëŸ‰ íŠ¹ì§• ì¤€ë¹„ ì™„ë£Œ: {len(result_df)} í–‰, {len(result_df.columns)} íŠ¹ì§•")
        return result_df
    
    def train(self, df: pd.DataFrame, feature_type: str = 'dispatch') -> Dict:
        """
        ëª¨ë¸ í•™ìŠµ
        
        Args:
            df: í•™ìŠµ ë°ì´í„°í”„ë ˆì„
            feature_type: íŠ¹ì§• ìœ í˜• ('dispatch' ë˜ëŠ” 'vehicle')
            
        Returns:
            Dict: í•™ìŠµ ê²°ê³¼ í†µê³„
        """
        # íŠ¹ì§• ì¤€ë¹„
        if feature_type == 'dispatch':
            features_df = self.prepare_dispatch_features(df)
        elif feature_type == 'vehicle':
            features_df = self.prepare_vehicle_features(df)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” feature_type: {feature_type}")
        
        self.feature_names = features_df.columns.tolist()
        
        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.fit_transform(features_df)
        
        logger.info(f"ğŸ¤– ì´ìƒ íƒì§€ ëª¨ë¸ í•™ìŠµ ì‹œì‘... ({len(X_scaled)} ìƒ˜í”Œ)")
        
        # ëª¨ë¸ í•™ìŠµ
        self.model.fit(X_scaled)
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(X_scaled)
        anomaly_scores = self.model.score_samples(X_scaled)
        
        self.is_trained = True
        
        # í†µê³„
        n_anomalies = (predictions == -1).sum()
        n_normal = (predictions == 1).sum()
        anomaly_ratio = n_anomalies / len(predictions) * 100
        
        stats = {
            'total_samples': len(predictions),
            'normal_count': int(n_normal),
            'anomaly_count': int(n_anomalies),
            'anomaly_ratio': float(anomaly_ratio),
            'min_score': float(anomaly_scores.min()),
            'max_score': float(anomaly_scores.max()),
            'mean_score': float(anomaly_scores.mean())
        }
        
        logger.info(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        logger.info(f"  ì „ì²´ ìƒ˜í”Œ: {stats['total_samples']}")
        logger.info(f"  ì •ìƒ: {stats['normal_count']} ({100 - anomaly_ratio:.1f}%)")
        logger.info(f"  ì´ìƒ: {stats['anomaly_count']} ({anomaly_ratio:.1f}%)")
        logger.info(f"  ì´ìƒ ì ìˆ˜ ë²”ìœ„: [{stats['min_score']:.3f}, {stats['max_score']:.3f}]")
        
        return stats
    
    def detect(self, df: pd.DataFrame, feature_type: str = 'dispatch',
               threshold: Optional[float] = None) -> pd.DataFrame:
        """
        ì´ìƒ íƒì§€
        
        Args:
            df: íƒì§€í•  ë°ì´í„°í”„ë ˆì„
            feature_type: íŠ¹ì§• ìœ í˜• ('dispatch' ë˜ëŠ” 'vehicle')
            threshold: ì´ìƒ ì ìˆ˜ ì„ê³„ê°’ (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: None)
            
        Returns:
            pd.DataFrame: ì›ë³¸ ë°ì´í„° + ì˜ˆì¸¡ ê²°ê³¼ + ì´ìƒ ì ìˆ˜
        """
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train() ë©”ì„œë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # íŠ¹ì§• ì¤€ë¹„
        if feature_type == 'dispatch':
            features_df = self.prepare_dispatch_features(df)
        elif feature_type == 'vehicle':
            features_df = self.prepare_vehicle_features(df)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” feature_type: {feature_type}")
        
        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.transform(features_df)
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(X_scaled)
        anomaly_scores = self.model.score_samples(X_scaled)
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        result_df = df.copy()
        result_df['is_anomaly'] = (predictions == -1).astype(int)
        result_df['anomaly_score'] = anomaly_scores
        
        # ì„ê³„ê°’ ì ìš© (ì„ íƒì‚¬í•­)
        if threshold is not None:
            result_df['is_anomaly'] = (anomaly_scores < threshold).astype(int)
        
        # ì´ìƒì¹˜ë§Œ í•„í„°ë§
        anomalies = result_df[result_df['is_anomaly'] == 1]
        
        logger.info(f"ğŸ” ì´ìƒ íƒì§€ ì™„ë£Œ:")
        logger.info(f"  ì „ì²´: {len(result_df)} ê±´")
        logger.info(f"  ì´ìƒ: {len(anomalies)} ê±´ ({len(anomalies)/len(result_df)*100:.1f}%)")
        
        if len(anomalies) > 0:
            logger.info(f"\nâš ï¸ ìƒìœ„ 5ê°œ ì´ìƒ íŒ¨í„´:")
            top_anomalies = anomalies.nsmallest(5, 'anomaly_score')
            for idx, row in top_anomalies.iterrows():
                logger.info(f"  Index {idx}: Score {row['anomaly_score']:.3f}")
        
        return result_df
    
    def get_anomaly_features(self, df: pd.DataFrame, 
                            feature_type: str = 'dispatch') -> pd.DataFrame:
        """
        ì´ìƒì¹˜ì˜ ì£¼ìš” íŠ¹ì§• ë¶„ì„
        
        Args:
            df: íƒì§€ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ (is_anomaly ì»¬ëŸ¼ í¬í•¨)
            feature_type: íŠ¹ì§• ìœ í˜•
            
        Returns:
            pd.DataFrame: íŠ¹ì§• í†µê³„ ë¹„êµ
        """
        if 'is_anomaly' not in df.columns:
            raise ValueError("ë°ì´í„°í”„ë ˆì„ì— 'is_anomaly' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŠ¹ì§• ì¤€ë¹„
        if feature_type == 'dispatch':
            features_df = self.prepare_dispatch_features(df)
        else:
            features_df = self.prepare_vehicle_features(df)
        
        # ì´ìƒì¹˜ì™€ ì •ìƒ ë°ì´í„° ë¶„ë¦¬
        anomaly_features = features_df[df['is_anomaly'] == 1]
        normal_features = features_df[df['is_anomaly'] == 0]
        
        # íŠ¹ì§•ë³„ í‰ê·  ë¹„êµ
        comparison = pd.DataFrame({
            'feature': self.feature_names,
            'normal_mean': normal_features.mean(),
            'anomaly_mean': anomaly_features.mean(),
        })
        
        comparison['diff_ratio'] = (
            (comparison['anomaly_mean'] - comparison['normal_mean']) / 
            comparison['normal_mean'].replace(0, 1)
        ).abs()
        
        # ì°¨ì´ê°€ í° ìˆœì„œë¡œ ì •ë ¬
        comparison = comparison.sort_values('diff_ratio', ascending=False)
        
        logger.info(f"\nğŸ“Š ì´ìƒì¹˜ ì£¼ìš” íŠ¹ì§• (ìƒìœ„ 5ê°œ):")
        for idx, row in comparison.head(5).iterrows():
            logger.info(f"  {row['feature']}:")
            logger.info(f"    ì •ìƒ í‰ê· : {row['normal_mean']:.2f}")
            logger.info(f"    ì´ìƒ í‰ê· : {row['anomaly_mean']:.2f}")
            logger.info(f"    ì°¨ì´ ë¹„ìœ¨: {row['diff_ratio']:.2%}")
        
        return comparison
    
    def save_model(self, path: str):
        """
        ëª¨ë¸ ì €ì¥
        
        Args:
            path: ì €ì¥ ê²½ë¡œ
        """
        if not self.is_trained:
            raise ValueError("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'is_trained': self.is_trained
        }
        
        joblib.dump(model_data, path)
        logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load_model(self, path: str):
        """
        ëª¨ë¸ ë¡œë“œ
        
        Args:
            path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        model_data = joblib.load(path)
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.feature_names = model_data['feature_names']
        self.is_trained = model_data['is_trained']
        logger.info(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import sys
    sys.path.append('/home/user/webapp/phase5')
    
    from ml_advanced.utils.data_loader import DataLoader
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # 1. ë°ì´í„° ë¡œë“œ
    loader = DataLoader()
    
    try:
        # ë°°ì°¨ ì´ë ¥ ë¡œë“œ (ìµœê·¼ 90ì¼)
        logger.info("ğŸ“Š ë°ì´í„° ë¡œë“œ ì‹œì‘...")
        dispatch_df = loader.load_dispatch_history(days=90)
        
        # 2. ëª¨ë¸ í•™ìŠµ
        detector = AnomalyDetector(contamination=0.1)
        stats = detector.train(dispatch_df, feature_type='dispatch')
        
        # 3. ì´ìƒ íƒì§€
        results = detector.detect(dispatch_df, feature_type='dispatch')
        
        # ì´ìƒì¹˜ë§Œ ì¶œë ¥
        anomalies = results[results['is_anomaly'] == 1]
        print(f"\nâš ï¸ íƒì§€ëœ ì´ìƒ ë°°ì°¨: {len(anomalies)} ê±´")
        print(anomalies[['dispatch_date', 'vehicle_number', 'total_distance_km', 
                        'total_duration_minutes', 'anomaly_score']].head())
        
        # 4. ì´ìƒì¹˜ íŠ¹ì§• ë¶„ì„
        feature_analysis = detector.get_anomaly_features(results, feature_type='dispatch')
        
        # 5. ëª¨ë¸ ì €ì¥
        model_path = '/home/user/webapp/phase5/models/anomaly_detector_model.pkl'
        detector.save_model(model_path)
        
    finally:
        loader.close()
