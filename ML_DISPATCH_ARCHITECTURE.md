# ğŸ¤– UVIS ML ê¸°ë°˜ ë°°ì°¨ í•™ìŠµ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

## ğŸ“‹ ê°œìš”

UVISì˜ ë³µì¡í•œ ë°°ì°¨ ì¡°ê±´ë“¤(17ê°€ì§€ ì œì•½ì‚¬í•­)ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ìµœì í™”í•˜ëŠ” ML ì‹œìŠ¤í…œ ì„¤ê³„ì…ë‹ˆë‹¤.

---

## ğŸ¯ í•µì‹¬ ì „ëµ: Multi-Agent í•™ìŠµ ì‹œìŠ¤í…œ

### ì™œ Multi-Agentì¸ê°€?

**ë‹¨ì¼ ëª¨ë¸ì˜ ë¬¸ì œì :**
- 17ê°€ì§€ ì œì•½ì¡°ê±´ì„ í•œ ëª¨ë¸ì´ í•™ìŠµ â†’ ê³¼ì í•©/ë³µì¡ë„ í­ë°œ
- ì‹ ê·œ ì œì•½ì¡°ê±´ ì¶”ê°€ ì‹œ ì „ì²´ ëª¨ë¸ ì¬í•™ìŠµ í•„ìš”
- ë””ë²„ê¹… ë° ê°œì„ ì´ ì–´ë ¤ì›€

**Multi-Agentì˜ ì¥ì :**
- ê° ì œì•½ì¡°ê±´ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸ í•™ìŠµ
- ë…ë¦½ì  ê°œì„  ê°€ëŠ¥ (A/B í…ŒìŠ¤íŠ¸ ìš©ì´)
- ë³‘ë ¬ í•™ìŠµ ë° ì¶”ë¡  ê°€ëŠ¥
- í•´ì„ ê°€ëŠ¥ì„±(Interpretability) í–¥ìƒ

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ë°°ì°¨ ìš”ì²­ (Orders)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Feature Engineering Layer                        â”‚
â”‚  - ì°¨ëŸ‰ ìƒíƒœ ë²¡í„°í™”                                           â”‚
â”‚  - ì£¼ë¬¸ íŠ¹ì„± ì¶”ì¶œ                                            â”‚
â”‚  - ì‹œê³µê°„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hard Rules     â”‚                   â”‚  ML Agents      â”‚
â”‚  Filtering      â”‚                   â”‚  Optimization   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1) ì˜¨ë„ëŒ€ ë§¤ì¹­   â”‚                   â”‚ Agent 1: ê±°ë¦¬   â”‚
â”‚ 2) íŒ”ë ›íŠ¸ íƒ€ì…   â”‚                   â”‚ Agent 2: íšŒì „ìˆ˜ â”‚
â”‚ 3) ìš©ëŸ‰ ì œì•½     â”‚                   â”‚ Agent 3: ê·¼ë¬´ì¼ â”‚
â”‚ 4) ê³ ì •ë°°ì°¨      â”‚                   â”‚ Agent 4: ì‹œê°„   â”‚
â”‚ 5) ê¸°í”¼ì°¨ëŸ‰      â”‚                   â”‚ Agent 5: ë¹„ìš©   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                                       â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Meta Coordinator â”‚
                   â”‚   (Ensemble)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ ìµœì¢… ë°°ì°¨ ê²°ì •   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Agent ìƒì„¸ ì„¤ê³„

### 1ï¸âƒ£ Agent ë¶„ë¥˜ ì „ëµ

#### **Tier 1: Hard Rules (í•„í„°ë§)**
ML í•™ìŠµ ë¶ˆí•„ìš”, ê·œì¹™ ê¸°ë°˜ í•„í„°ë§:
- âœ… ì˜¨ë„ëŒ€ ë§¤ì¹­ (ëƒ‰ë™/ëƒ‰ì¥/ìƒì˜¨)
- âœ… íŒ”ë ›íŠ¸ íƒ€ì… (11í˜•/12í˜•)
- âœ… ìš©ëŸ‰ ì œì•½ (max_pallets, ì°¨ëŸ‰ ê¸¸ì´)
- âœ… ê³ ì •ë°°ì°¨ (íŠ¹ì • ì°¨ëŸ‰-ê±°ë˜ì²˜ ê³ ì •)
- âœ… ê¸°í”¼ì°¨ëŸ‰ (ê±°ë˜ì²˜ë³„ ê¸°í”¼ ì°¨ëŸ‰)

**êµ¬í˜„:**
```python
def hard_filter_vehicles(orders: List[Order], vehicles: List[Vehicle]) -> Dict[int, List[Vehicle]]:
    """ê° ì£¼ë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œ ì°¨ëŸ‰ë§Œ í•„í„°ë§"""
    eligible = {}
    
    for order in orders:
        candidates = []
        for vehicle in vehicles:
            # ì˜¨ë„ëŒ€ ì²´í¬
            if not is_temperature_compatible(vehicle, order.temperature_zone):
                continue
            
            # íŒ”ë ›íŠ¸ íƒ€ì… ì²´í¬
            if not check_pallet_capacity(vehicle, order.pallet_type, order.pallet_count):
                continue
            
            # ê³ ì •ë°°ì°¨ ì²´í¬
            if order.client_id in vehicle.fixed_clients:
                candidates.insert(0, vehicle)  # ìµœìš°ì„ 
            elif vehicle.id in order.client.blocked_vehicles:
                continue  # ê¸°í”¼ì°¨ëŸ‰ ì œì™¸
            else:
                candidates.append(vehicle)
        
        eligible[order.id] = candidates
    
    return eligible
```

---

#### **Tier 2: Soft Constraints (ML ìµœì í™”)**
í•™ìŠµ ê¸°ë°˜ ì˜ì‚¬ê²°ì •:

##### **Agent 1: Distance Optimizer** ğŸ›£ï¸
- **ëª©ì :** ê³µì°¨ ê±°ë¦¬ ìµœì†Œí™” (150km ê¸°ì¤€)
- **ì…ë ¥:** 
  - ì°¨ëŸ‰ í˜„ìœ„ì¹˜ (GPS or ì°¨ê³ ì§€)
  - ìƒì°¨ì§€ ìœ„ì¹˜
  - í•˜ì°¨ì§€ ìœ„ì¹˜
- **ì¶œë ¥:** Distance Score (0~1, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **ëª¨ë¸:** Gradient Boosting (LightGBM)
- **í•™ìŠµ ë°ì´í„°:** ê³¼ê±° ë°°ì°¨ â†’ ì‹¤ì œ ê³µì°¨ ê±°ë¦¬ ê¸°ë¡

```python
class DistanceOptimizer:
    def __init__(self):
        self.model = lgb.LGBMRegressor(
            objective='regression',
            n_estimators=100,
            max_depth=5
        )
    
    def compute_score(self, vehicle, order):
        features = [
            haversine(vehicle.current_lat, vehicle.current_lon, order.pickup_lat, order.pickup_lon),
            haversine(order.pickup_lat, order.pickup_lon, order.delivery_lat, order.delivery_lon),
            haversine(order.delivery_lat, order.delivery_lon, vehicle.garage_lat, vehicle.garage_lon),
            vehicle.fuel_efficiency_km_per_liter,
            order.priority
        ]
        
        # ì˜ˆì¸¡: ì´ ì£¼í–‰ ê±°ë¦¬
        predicted_distance = self.model.predict([features])[0]
        
        # 150km ê¸°ì¤€ ì •ê·œí™”
        score = min(predicted_distance / 150.0, 2.0)  # 150km ë„˜ìœ¼ë©´ í˜ë„í‹°
        return score
```

##### **Agent 2: Rotation Equalizer** ğŸ”„
- **ëª©ì :** ì°¨ëŸ‰ íšŒì „ìˆ˜ í‰ì¤€í™” (ì›”ê¸‰ ê³µì •ì„±)
- **ì…ë ¥:**
  - ì°¨ëŸ‰ë³„ ë‹¹ì›” íšŒì „ìˆ˜
  - ì°¨ëŸ‰ë³„ ë‹¹ì›” ê²½ìœ  íšŸìˆ˜
  - ì°¨ëŸ‰ë³„ ë‹¹ì›” ê·¼ë¬´ì¼ìˆ˜
- **ì¶œë ¥:** Fairness Score (0~1, ë‚®ì„ìˆ˜ë¡ í‰ë“±)
- **ëª¨ë¸:** Neural Network (Fairness Loss)

```python
import torch
import torch.nn as nn

class RotationEqualizer(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(5, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )
    
    def forward(self, vehicle_stats):
        """
        vehicle_stats: [
            vehicle.rotation_count_this_month,
            vehicle.waypoint_count_this_month,
            vehicle.work_days_this_month,
            avg_rotation_count,  # ì „ì²´ ì°¨ëŸ‰ í‰ê· 
            avg_work_days
        ]
        """
        return self.net(vehicle_stats)
    
    def fairness_loss(self, predictions, targets):
        """íšŒì „ìˆ˜ í¸ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜"""
        variance = torch.var(predictions)
        mse = nn.MSELoss()(predictions, targets)
        return mse + 0.3 * variance  # í¸ì°¨ í˜ë„í‹°
```

##### **Agent 3: Time Window Checker** â°
- **ëª©ì :** í•˜ì°¨ ê°€ëŠ¥ ì‹œê°„ ì¤€ìˆ˜ (24ì‹œê°„ ê¸°ì¤€)
- **ì…ë ¥:**
  - í˜„ì¬ ì‹œê°
  - ì˜ˆìƒ ìƒì°¨ ì‹œê°
  - í•˜ì°¨ ê°€ëŠ¥ ì‹œê°„ (start, end)
  - ìš´í–‰ ì˜ˆìƒ ì‹œê°„ (ETA)
- **ì¶œë ¥:** Time Feasibility Score (0~1, 1=ì™„ë²½ ë§¤ì¹­)
- **ëª¨ë¸:** RNN (ì‹œê³„ì—´ ì˜ˆì¸¡)

```python
import torch.nn as nn

class TimeWindowChecker(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(input_size=6, hidden_size=32, num_layers=2, batch_first=True)
        self.fc = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, time_sequence):
        """
        time_sequence: [batch, seq_len, 6]
        - seq_len: ê³¼ê±° 5ê°œ ì£¼ë¬¸ì˜ ì‹œê°„ íŒ¨í„´
        - 6 features: [hour, minute, pickup_duration, driving_duration, delivery_duration, buffer]
        """
        lstm_out, _ = self.lstm(time_sequence)
        last_hidden = lstm_out[:, -1, :]
        score = self.sigmoid(self.fc(last_hidden))
        return score
```

##### **Agent 4: Vehicle Preference Matcher** ğŸ¯
- **ëª©ì :** ê³ ì •ë°°ì°¨ ìš°ì„ ìˆœìœ„ & ì„ í˜¸ í•˜ì°¨ì§€
- **ì…ë ¥:**
  - ì°¨ëŸ‰ ì„ í˜¸ í•˜ì°¨ì§€ ë¦¬ìŠ¤íŠ¸
  - ì£¼ë¬¸ í•˜ì°¨ì§€
  - ê³ ì •ë°°ì°¨ ì—¬ë¶€
- **ì¶œë ¥:** Preference Score (0~1, 1=ìµœìš°ì„ )
- **ëª¨ë¸:** Decision Tree (í•´ì„ ê°€ëŠ¥)

```python
from sklearn.tree import DecisionTreeClassifier

class VehiclePreferenceMatcher:
    def __init__(self):
        self.model = DecisionTreeClassifier(max_depth=4, random_state=42)
    
    def compute_score(self, vehicle, order):
        features = [
            1.0 if order.delivery_client_id in vehicle.preferred_delivery_clients else 0.0,
            1.0 if order.is_fixed_dispatch and vehicle.id in order.fixed_vehicles else 0.0,
            1.0 if vehicle.is_one_way_fixed else 0.0,
            vehicle.priority_level  # 1~5
        ]
        
        # ì´ì§„ ë¶„ë¥˜: ìš°ì„ ë°°ì°¨ ì—¬ë¶€ (0 or 1)
        is_priority = self.model.predict([features])[0]
        
        # ì ìˆ˜ ë³€í™˜
        score = 1.0 if is_priority == 1 else 0.5
        return score
```

##### **Agent 5: Voltage Alert Monitor** ğŸ”‹
- **ëª©ì :** ì €ì „ì•• ì°¨ëŸ‰ ë°°ì œ (ì•ˆì „)
- **ì…ë ¥:**
  - ì°¨ëŸ‰ í˜„ì¬ ì „ì•• (UVIS GPS)
  - ì‹œë™ ìƒíƒœ (ON/OFF)
- **ì¶œë ¥:** Safety Score (0 or 1, 1=ì•ˆì „)
- **ëª¨ë¸:** Rule-based (ML ë¶ˆí•„ìš”)

```python
def voltage_safety_check(vehicle, uvis_data):
    """ì €ì „ì•• ì°¨ëŸ‰ í•„í„°ë§"""
    if uvis_data['engine_on']:
        # ì‹œë™ ON: 26V ë¯¸ë§Œ ê²½ê³ 
        if uvis_data['voltage'] < 26.0:
            logger.warning(f"Vehicle {vehicle.code}: Low voltage {uvis_data['voltage']}V (engine ON)")
            return 0.0  # ë°°ì°¨ ë¶ˆê°€
    else:
        # ì‹œë™ OFF: 24V ë¯¸ë§Œ ê²½ê³ 
        if uvis_data['voltage'] < 24.0:
            logger.warning(f"Vehicle {vehicle.code}: Low voltage {uvis_data['voltage']}V (engine OFF)")
            return 0.0
    
    return 1.0  # ì•ˆì „
```

---

### 2ï¸âƒ£ Meta Coordinator (ì•™ìƒë¸”)

ëª¨ë“  Agentì˜ ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ ìµœì¢… ê²°ì •:

```python
class MetaCoordinator:
    def __init__(self):
        self.weights = {
            'distance': 0.25,      # ê±°ë¦¬ ì¤‘ìš”ë„
            'rotation': 0.20,      # íšŒì „ìˆ˜ í‰ë“± ì¤‘ìš”ë„
            'time_window': 0.25,   # ì‹œê°„ ì¤€ìˆ˜ ì¤‘ìš”ë„
            'preference': 0.15,    # ì„ í˜¸ ë§¤ì¹­ ì¤‘ìš”ë„
            'voltage': 0.15        # ì•ˆì „ ì¤‘ìš”ë„
        }
    
    def compute_final_score(self, agent_scores: Dict[str, float]) -> float:
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        final_score = 0.0
        
        for agent_name, score in agent_scores.items():
            final_score += self.weights[agent_name] * score
        
        return final_score
    
    def rank_vehicles(self, order: Order, candidates: List[Vehicle]) -> List[Tuple[Vehicle, float]]:
        """ì°¨ëŸ‰ ìˆœìœ„ ë§¤ê¸°ê¸°"""
        rankings = []
        
        for vehicle in candidates:
            scores = {
                'distance': distance_optimizer.compute_score(vehicle, order),
                'rotation': rotation_equalizer.compute_score(vehicle),
                'time_window': time_window_checker.compute_score(vehicle, order),
                'preference': preference_matcher.compute_score(vehicle, order),
                'voltage': voltage_safety_check(vehicle, uvis_gps_data[vehicle.id])
            }
            
            # ì „ì•• 0ì ì´ë©´ ì¦‰ì‹œ ì œì™¸
            if scores['voltage'] == 0.0:
                continue
            
            final_score = self.compute_final_score(scores)
            rankings.append((vehicle, final_score))
        
        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        rankings.sort(key=lambda x: x[1], reverse=True)
        
        return rankings
```

---

## ğŸ“Š í•™ìŠµ ë°ì´í„° êµ¬ì¡°

### 1ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘

```sql
-- í•™ìŠµìš© ë°°ì°¨ ì´ë ¥ í…Œì´ë¸”
CREATE TABLE dispatch_training_data (
    id SERIAL PRIMARY KEY,
    dispatch_id INTEGER REFERENCES dispatches(id),
    order_id INTEGER REFERENCES orders(id),
    vehicle_id INTEGER REFERENCES vehicles(id),
    
    -- Feature columns
    vehicle_distance_km FLOAT,           -- ê³µì°¨ ê±°ë¦¬
    vehicle_rotation_count INTEGER,      -- ë‹¹ì‹œ íšŒì „ìˆ˜
    time_window_slack_minutes INTEGER,   -- ì—¬ìœ  ì‹œê°„
    is_preferred_match BOOLEAN,          -- ì„ í˜¸ ë§¤ì¹­ ì—¬ë¶€
    voltage_at_dispatch FLOAT,           -- ë°°ì°¨ ì‹œ ì „ì••
    
    -- Target columns (ì‹¤ì œ ê²°ê³¼)
    actual_total_distance_km FLOAT,      -- ì‹¤ì œ ì£¼í–‰ ê±°ë¦¬
    actual_arrival_time TIMESTAMP,       -- ì‹¤ì œ ë„ì°© ì‹œê°„
    was_delayed BOOLEAN,                 -- ì§€ì—° ì—¬ë¶€
    driver_satisfaction INTEGER,         -- ê¸°ì‚¬ ë§Œì¡±ë„ (1~5)
    
    -- Metadata
    assigned_by VARCHAR(50),             -- 'human' or 'ml'
    created_at TIMESTAMP DEFAULT NOW()
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_training_vehicle ON dispatch_training_data(vehicle_id);
CREATE INDEX idx_training_order ON dispatch_training_data(order_id);
CREATE INDEX idx_training_date ON dispatch_training_data(created_at);
```

### 2ï¸âƒ£ Feature Engineering

```python
def extract_features(order: Order, vehicle: Vehicle, context: Dict) -> np.ndarray:
    """ì£¼ë¬¸-ì°¨ëŸ‰ ìŒì—ì„œ í•™ìŠµ íŠ¹ì§• ì¶”ì¶œ"""
    features = []
    
    # ê±°ë¦¬ ê´€ë ¨
    features.append(haversine(vehicle.current_lat, vehicle.current_lon, order.pickup_lat, order.pickup_lon))
    features.append(haversine(order.pickup_lat, order.pickup_lon, order.delivery_lat, order.delivery_lon))
    
    # ì°¨ëŸ‰ ìƒíƒœ
    features.append(vehicle.rotation_count_this_month)
    features.append(vehicle.work_days_this_month)
    features.append(vehicle.waypoint_count_this_month)
    
    # ì‹œê°„ ê´€ë ¨
    features.append(context['current_hour'])
    features.append(context['day_of_week'])
    features.append(order.delivery_time_window_slack)
    
    # ì„ í˜¸ë„
    features.append(1.0 if order.delivery_client_id in vehicle.preferred_clients else 0.0)
    features.append(1.0 if order.is_fixed_dispatch else 0.0)
    
    # ì•ˆì „
    features.append(context.get('voltage', 26.0))
    
    return np.array(features)
```

---

## ğŸš€ í•™ìŠµ íŒŒì´í”„ë¼ì¸

### Phase 1: ì˜¤í”„ë¼ì¸ í•™ìŠµ (ì´ˆê¸°)

```python
# 1. ê³¼ê±° ë°ì´í„° ë¡œë“œ
df = pd.read_sql("""
    SELECT * FROM dispatch_training_data
    WHERE created_at >= NOW() - INTERVAL '6 months'
      AND assigned_by = 'human'
""", engine)

# 2. Feature ìƒì„±
X = []
y = []

for row in df.itertuples():
    features = extract_features(row.order, row.vehicle, row.context)
    X.append(features)
    
    # Target: ë°°ì°¨ ì„±ê³µ ì—¬ë¶€ (ê±°ë¦¬ + ì§€ì—° ê³ ë ¤)
    success_score = (
        (1.0 - min(row.actual_total_distance_km / 150.0, 2.0)) * 0.4 +  # ê±°ë¦¬ ì ìˆ˜
        (1.0 if not row.was_delayed else 0.0) * 0.4 +                    # ì§€ì—° ì ìˆ˜
        (row.driver_satisfaction / 5.0) * 0.2                            # ë§Œì¡±ë„ ì ìˆ˜
    )
    y.append(success_score)

X = np.array(X)
y = np.array(y)

# 3. Agentë³„ í•™ìŠµ
distance_optimizer.fit(X, y)
rotation_equalizer.fit(X, y)
time_window_checker.fit(X, y)

# 4. ëª¨ë¸ ì €ì¥
joblib.dump(distance_optimizer, 'models/distance_optimizer_v1.pkl')
```

### Phase 2: ì˜¨ë¼ì¸ í•™ìŠµ (ì§€ì† ê°œì„ )

```python
class OnlineLearner:
    def __init__(self):
        self.buffer = []
        self.batch_size = 100
        
    def add_feedback(self, dispatch_id: int, feedback: Dict):
        """ì‹¤ì‹œê°„ í”¼ë“œë°± ìˆ˜ì§‘"""
        self.buffer.append({
            'dispatch_id': dispatch_id,
            'feedback': feedback,
            'timestamp': datetime.now()
        })
        
        # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ í•™ìŠµ
        if len(self.buffer) >= self.batch_size:
            self.update_models()
    
    def update_models(self):
        """ëª¨ë¸ ì¦ë¶„ ì—…ë°ì´íŠ¸"""
        logger.info(f"Updating models with {len(self.buffer)} new samples...")
        
        # ìƒˆ ë°ì´í„°ë¡œ ëª¨ë¸ fine-tuning
        for agent in [distance_optimizer, rotation_equalizer, time_window_checker]:
            X_new, y_new = self._prepare_batch(self.buffer)
            agent.partial_fit(X_new, y_new)
        
        # ë²„í¼ ì´ˆê¸°í™”
        self.buffer.clear()
        
        logger.info("Models updated successfully!")
```

---

## ğŸ® ì‹¤ì „ ë°°ì°¨ í”Œë¡œìš°

```python
async def optimize_dispatch(orders: List[Order], vehicles: List[Vehicle]) -> List[Dispatch]:
    """ML ê¸°ë°˜ ìµœì  ë°°ì°¨ ìƒì„±"""
    
    # Step 1: Hard Filter
    eligible = hard_filter_vehicles(orders, vehicles)
    logger.info(f"Hard filtering: {sum(len(v) for v in eligible.values())} candidates")
    
    # Step 2: ML Agent ì ìˆ˜ ê³„ì‚°
    dispatches = []
    
    for order in orders:
        candidates = eligible[order.id]
        
        if not candidates:
            logger.warning(f"No eligible vehicles for order {order.order_number}")
            # ìš©ì°¨ ìˆ˜ë°° ë¡œì§ìœ¼ë¡œ ì´ë™
            continue
        
        # Meta Coordinatorë¡œ ìˆœìœ„ ê²°ì •
        rankings = meta_coordinator.rank_vehicles(order, candidates)
        
        # ìµœê³  ì ìˆ˜ ì°¨ëŸ‰ ì„ íƒ
        best_vehicle, best_score = rankings[0]
        
        logger.info(f"Order {order.order_number} â†’ Vehicle {best_vehicle.code} (score: {best_score:.3f})")
        
        # Dispatch ìƒì„±
        dispatch = Dispatch(
            order_id=order.id,
            vehicle_id=best_vehicle.id,
            optimization_score=best_score,
            assigned_by='ml',
            status=DispatchStatus.ASSIGNED
        )
        dispatches.append(dispatch)
    
    # Step 3: TSPë¡œ ê²½ë¡œ ìµœì í™”
    for dispatch in dispatches:
        routes = await tsp_optimizer.optimize_routes([dispatch.order])
        dispatch.routes = routes
    
    return dispatches
```

---

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ (KPIs)

### 1ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥

```python
# Metrics ê³„ì‚°
from sklearn.metrics import mean_squared_error, r2_score

def evaluate_agents():
    metrics = {}
    
    # Distance Optimizer
    y_pred_dist = distance_optimizer.predict(X_test)
    metrics['distance_mae'] = mean_absolute_error(y_test_distance, y_pred_dist)
    metrics['distance_r2'] = r2_score(y_test_distance, y_pred_dist)
    
    # Rotation Equalizer
    rotation_variance = np.var([v.rotation_count for v in vehicles])
    metrics['rotation_fairness'] = 1.0 / (1.0 + rotation_variance)  # í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ 1ì— ê°€ê¹Œì›€
    
    # Time Window Checker
    on_time_rate = np.mean([1 if not d.was_delayed else 0 for d in dispatches])
    metrics['time_window_accuracy'] = on_time_rate
    
    logger.info(f"Model Performance: {metrics}")
    return metrics
```

### 2ï¸âƒ£ ë¹„ì¦ˆë‹ˆìŠ¤ KPIs

- **ê³µì°¨ ê±°ë¦¬:** í‰ê·  100km ì´í•˜ (ëª©í‘œ 150km ëŒ€ë¹„ 33% ê°œì„ )
- **íšŒì „ìˆ˜ í¸ì°¨:** ì›”ë³„ í‘œì¤€í¸ì°¨ 2íšŒ ì´í•˜
- **ì‹œê°„ ì¤€ìˆ˜ìœ¨:** 95% ì´ìƒ
- **ìš©ì°¨ ìˆ˜ë°°ìœ¨:** 10% ì´í•˜ (90% ìì‚¬ ì°¨ëŸ‰ ë°°ì°¨)
- **ê¸°ì‚¬ ë§Œì¡±ë„:** í‰ê·  4.0/5.0 ì´ìƒ

---

## ğŸ”„ ì§€ì† ê°œì„  ì‚¬ì´í´

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë°°ì°¨ ì‹¤í–‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‹¤ì‹œê°„ ì¶”ì  â”‚ (GPS, ETA)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ê²°ê³¼ ìˆ˜ì§‘   â”‚ (ê±°ë¦¬, ì‹œê°„, ë§Œì¡±ë„)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ëª¨ë¸ ì¬í•™ìŠµ â”‚ (Online Learning)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê°€ì¤‘ì¹˜ ì¡°ì •  â”‚ (Meta Coordinator)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
       â””â”€â”€â”€â”€â”€â”€â†’ (ë°˜ë³µ)
```

### A/B í…ŒìŠ¤íŠ¸ ì „ëµ

```python
class ABTestingController:
    def __init__(self):
        self.test_groups = {
            'control': 0.7,    # 70%: ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜
            'ml_v1': 0.15,     # 15%: ML Agent ë²„ì „ 1
            'ml_v2': 0.15      # 15%: ML Agent ë²„ì „ 2
        }
    
    def assign_dispatch_method(self, order: Order) -> str:
        """ì£¼ë¬¸ì„ ëœë¤í•˜ê²Œ ê·¸ë£¹ ë°°ì •"""
        rand = random.random()
        
        cumulative = 0.0
        for group, ratio in self.test_groups.items():
            cumulative += ratio
            if rand < cumulative:
                return group
        
        return 'control'
    
    def compare_results(self):
        """ê·¸ë£¹ë³„ ì„±ê³¼ ë¹„êµ"""
        results = {}
        
        for group in self.test_groups.keys():
            dispatches = Dispatch.query.filter_by(test_group=group).all()
            
            results[group] = {
                'avg_distance': np.mean([d.total_distance_km for d in dispatches]),
                'on_time_rate': np.mean([1 if not d.was_delayed else 0 for d in dispatches]),
                'satisfaction': np.mean([d.driver_satisfaction for d in dispatches])
            }
        
        logger.info(f"A/B Test Results: {results}")
        return results
```

---

## ğŸ› ï¸ êµ¬í˜„ ë¡œë“œë§µ

### **Week 1-2: ì¸í”„ë¼ êµ¬ì¶•**
- [ ] `dispatch_training_data` í…Œì´ë¸” ìƒì„±
- [ ] Feature extraction íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [ ] ê³¼ê±° 6ê°œì›” ë°ì´í„° ìˆ˜ì§‘ ë° ë¼ë²¨ë§

### **Week 3-4: Agent ê°œë°œ**
- [ ] Distance Optimizer í•™ìŠµ ë° ê²€ì¦
- [ ] Rotation Equalizer í•™ìŠµ ë° ê²€ì¦
- [ ] Time Window Checker í•™ìŠµ ë° ê²€ì¦
- [ ] Meta Coordinator ê°€ì¤‘ì¹˜ íŠœë‹

### **Week 5-6: í†µí•© ë° í…ŒìŠ¤íŠ¸**
- [ ] Hard Rules + ML Agents í†µí•©
- [ ] ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ (ê³¼ê±° ë°ì´í„° ì¬ìƒ)
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ê¸°ì¡´ vs ML)

### **Week 7-8: íŒŒì¼ëŸ¿ ëŸ°**
- [ ] 10% íŠ¸ë˜í”½ìœ¼ë¡œ A/B í…ŒìŠ¤íŠ¸
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- [ ] í”¼ë“œë°± ìˆ˜ì§‘ ë° ëª¨ë¸ ê°œì„ 

### **Week 9-10: ì „ì²´ ë¡¤ì•„ì›ƒ**
- [ ] 70% íŠ¸ë˜í”½ í™•ëŒ€
- [ ] Online Learning í™œì„±í™”
- [ ] ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- [Deep Reinforcement Learning for Vehicle Routing](https://arxiv.org/abs/1802.04240)
- [Learning to Dispatch for Ride-Sharing](https://dl.acm.org/doi/10.1145/3292500.3330978)

### ì˜¤í”ˆì†ŒìŠ¤
- **OR-Tools:** Googleì˜ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Gym-VRP:** ì°¨ëŸ‰ ê²½ë¡œ ìµœì í™” ê°•í™”í•™ìŠµ í™˜ê²½
- **LightGBM:** Gradient Boosting í”„ë ˆì„ì›Œí¬

---

## âœ… ìš”ì•½

### í•µì‹¬ ì „ëµ
1. **Multi-Agent ì•„í‚¤í…ì²˜:** 17ê°œ ì œì•½ì¡°ê±´ì„ 5ê°œ ì „ë¬¸ Agentë¡œ ë¶„ì‚°
2. **Hybrid ì ‘ê·¼:** Hard Rules (í•„í„°ë§) + ML (ìµœì í™”)
3. **ì§€ì† í•™ìŠµ:** ì˜¨ë¼ì¸ í•™ìŠµìœ¼ë¡œ ì‹¤ì‹œê°„ ê°œì„ 
4. **A/B í…ŒìŠ¤íŠ¸:** ì•ˆì „í•œ ì ì§„ì  ë°°í¬

### ì˜ˆìƒ íš¨ê³¼
- ğŸš€ **ê³µì°¨ ê±°ë¦¬:** 30% ê°ì†Œ
- âš–ï¸ **íšŒì „ìˆ˜ í¸ì°¨:** 50% ê°ì†Œ
- â° **ì‹œê°„ ì¤€ìˆ˜ìœ¨:** 95% ë‹¬ì„±
- ğŸ’° **ìš´ì˜ ë¹„ìš©:** ì—° 20% ì ˆê°

---

**ë‹¤ìŒ ë‹¨ê³„:** `backend/app/services/ml_dispatch_service.py` êµ¬í˜„ ì‹œì‘! ğŸš€
