"""
Phase 15: ML Auto-Learning API Endpoints
ê°•í™”í•™ìŠµ ê¸°ë°˜ ìë™ í•™ìŠµ ì‹œìŠ¤í…œ
"""
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta

from app.core.database import get_db
from app.api.auth import get_current_user
from app.models.user import User
from app.services.dispatch_data_collector import DispatchDataCollector
from app.services.rl_training_service import RLTrainingService
from app.models.ml_training import MLExperiment, ModelVersion

router = APIRouter()


# ==================== ë°ì´í„° ìˆ˜ì§‘ ====================

@router.post("/ml/collect-dispatch-data")
async def collect_dispatch_data(
    dispatch_id: int,
    vehicle_id: int,
    order_id: int,
    episode_id: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ë°°ì°¨ ë°ì´í„° ìˆ˜ì§‘
    
    **ë°°ì°¨ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘**
    """
    collector = DispatchDataCollector(db)
    result = await collector.collect_dispatch_data(
        dispatch_id=dispatch_id,
        vehicle_id=vehicle_id,
        order_id=order_id,
        episode_id=episode_id
    )
    
    if not result:
        raise HTTPException(status_code=400, detail="Failed to collect data")
    
    return {
        "success": True,
        "data": result
    }


@router.post("/ml/update-reward/{training_data_id}")
async def update_training_reward(
    training_data_id: int,
    completion_time: float,
    distance: float,
    success: bool,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    í•™ìŠµ ë°ì´í„° ë³´ìƒ ì—…ë°ì´íŠ¸
    
    **ë°°ì°¨ ì™„ë£Œ í›„ í˜¸ì¶œë˜ì–´ ë³´ìƒ(Reward) ê³„ì‚°**
    """
    collector = DispatchDataCollector(db)
    reward_info = await collector.update_reward(
        training_data_id=training_data_id,
        completion_time=completion_time,
        distance=distance,
        success=success
    )
    
    if not reward_info:
        raise HTTPException(status_code=404, detail="Training data not found")
    
    return {
        "success": True,
        "reward": reward_info
    }


@router.get("/ml/training-data")
async def get_training_data(
    limit: int = Query(100, ge=1, le=1000),
    min_reward: Optional[float] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    í•™ìŠµ ë°ì´í„°ì…‹ ì¡°íšŒ
    
    **ìˆ˜ì§‘ëœ ë°°ì°¨ ë°ì´í„° í™•ì¸ ë° ë¶„ì„**
    """
    collector = DispatchDataCollector(db)
    dataset = await collector.get_training_dataset(
        limit=limit,
        min_reward=min_reward
    )
    
    return {
        "total": len(dataset),
        "data": dataset
    }


# ==================== í•™ìŠµ ì‹¤í—˜ ====================

@router.post("/ml/experiments")
async def create_experiment(
    experiment_name: str,
    hyperparameters: Dict[str, Any],
    description: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ìƒˆë¡œìš´ í•™ìŠµ ì‹¤í—˜ ìƒì„±
    
    **í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •í•˜ê³  ì‹¤í—˜ ì‹œì‘**
    
    Example hyperparameters:
    ```json
    {
        "learning_rate": 0.0003,
        "gamma": 0.99,
        "clip_range": 0.2,
        "n_steps": 2048
    }
    ```
    """
    trainer = RLTrainingService(db)
    result = await trainer.create_experiment(
        experiment_name=experiment_name,
        hyperparameters=hyperparameters,
        description=description
    )
    
    return result


@router.post("/ml/experiments/{experiment_id}/train")
async def start_training(
    experiment_id: int,
    epochs: int = Query(100, ge=1, le=1000),
    batch_size: int = Query(32, ge=1, le=256),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    í•™ìŠµ ì‹œì‘
    
    **ì‹¤í—˜ IDë¡œ í•™ìŠµ ì‹¤í–‰**
    """
    trainer = RLTrainingService(db)
    result = await trainer.start_training(
        experiment_id=experiment_id,
        epochs=epochs,
        batch_size=batch_size
    )
    
    return result


@router.get("/ml/experiments/{experiment_id}/progress")
async def get_training_progress(
    experiment_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    í•™ìŠµ ì§„í–‰ ìƒí™© ì¡°íšŒ
    
    **ì‹¤ì‹œê°„ í•™ìŠµ ìƒíƒœ ë° ë©”íŠ¸ë¦­ í™•ì¸**
    """
    trainer = RLTrainingService(db)
    progress = await trainer.get_training_progress(experiment_id)
    
    return progress


@router.get("/ml/experiments")
async def list_experiments(
    skip: int = 0,
    limit: int = 20,
    status: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ì‹¤í—˜ ëª©ë¡ ì¡°íšŒ
    
    **ëª¨ë“  í•™ìŠµ ì‹¤í—˜ ì´ë ¥ í™•ì¸**
    """
    query = db.query(MLExperiment)
    
    if status:
        query = query.filter(MLExperiment.status == status)
    
    experiments = query.order_by(
        MLExperiment.created_at.desc()
    ).offset(skip).limit(limit).all()
    
    results = []
    for exp in experiments:
        results.append({
            "id": exp.id,
            "experiment_name": exp.experiment_name,
            "experiment_type": exp.experiment_type,
            "status": exp.status,
            "best_reward": exp.best_reward,
            "best_epoch": exp.best_epoch,
            "started_at": exp.started_at.isoformat() if exp.started_at else None,
            "completed_at": exp.completed_at.isoformat() if exp.completed_at else None,
            "duration_seconds": exp.duration_seconds
        })
    
    return {
        "total": len(results),
        "experiments": results
    }


# ==================== ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ====================

@router.post("/ml/models")
async def create_model_version(
    experiment_id: int,
    version: str,
    model_name: str = "PPO_Dispatch",
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ëª¨ë¸ ë²„ì „ ìƒì„±
    
    **í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥ ë° ë²„ì „ ê´€ë¦¬**
    """
    trainer = RLTrainingService(db)
    result = await trainer.create_model_version(
        experiment_id=experiment_id,
        version=version,
        model_name=model_name
    )
    
    return result


@router.post("/ml/models/{model_id}/deploy")
async def deploy_model(
    model_id: int,
    ab_test_traffic: float = Query(0.1, ge=0.0, le=1.0),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ëª¨ë¸ ë°°í¬ (A/B í…ŒìŠ¤íŠ¸)
    
    **ê²€ì¦ëœ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ì— ë°°í¬**
    
    - ab_test_traffic: A/B í…ŒìŠ¤íŠ¸ íŠ¸ë˜í”½ ë¹„ìœ¨ (0.0 ~ 1.0)
      - 0.1 = 10% íŠ¸ë˜í”½ì— ìƒˆ ëª¨ë¸ ì ìš©
      - 1.0 = 100% ì „ì²´ ì ìš©
    """
    trainer = RLTrainingService(db)
    result = await trainer.deploy_model(
        model_id=model_id,
        ab_test_traffic=ab_test_traffic
    )
    
    return result


@router.get("/ml/models")
async def list_models(
    skip: int = 0,
    limit: int = 20,
    is_active: Optional[bool] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ëª¨ë¸ ë²„ì „ ëª©ë¡ ì¡°íšŒ
    
    **ëª¨ë“  ëª¨ë¸ ë²„ì „ ë° ë°°í¬ ìƒíƒœ í™•ì¸**
    """
    query = db.query(ModelVersion)
    
    if is_active is not None:
        query = query.filter(ModelVersion.is_active == is_active)
    
    models = query.order_by(
        ModelVersion.created_at.desc()
    ).offset(skip).limit(limit).all()
    
    results = []
    for model in models:
        results.append({
            "id": model.id,
            "version": model.version,
            "model_name": model.model_name,
            "model_type": model.model_type,
            "status": model.status,
            "is_active": model.is_active,
            "deployed_at": model.deployed_at.isoformat() if model.deployed_at else None,
            "ab_test_traffic_percent": model.ab_test_traffic_percent,
            "performance_metrics": model.performance_metrics,
            "created_at": model.created_at.isoformat()
        })
    
    return {
        "total": len(results),
        "models": results
    }


@router.get("/ml/models/active")
async def get_active_model(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    í˜„ì¬ í™œì„± ëª¨ë¸ ì¡°íšŒ
    
    **í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´**
    """
    active_model = db.query(ModelVersion).filter(
        ModelVersion.is_active == True
    ).first()
    
    if not active_model:
        return {
            "active": False,
            "message": "No active model deployed"
        }
    
    return {
        "active": True,
        "model": {
            "id": active_model.id,
            "version": active_model.version,
            "model_name": active_model.model_name,
            "model_type": active_model.model_type,
            "deployed_at": active_model.deployed_at.isoformat() if active_model.deployed_at else None,
            "ab_test_traffic_percent": active_model.ab_test_traffic_percent,
            "performance_metrics": active_model.performance_metrics
        }
    }


# ==================== ì‹¤ì‹œê°„ ì˜ˆì¸¡ ====================

@router.post("/ml/predict")
async def predict_dispatch(
    state_features: Dict[str, Any],
    model_version: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    AI ë°°ì°¨ ì˜ˆì¸¡
    
    **í•™ìŠµëœ ëª¨ë¸ë¡œ ìµœì  ì°¨ëŸ‰ ì¶”ì²œ**
    
    Example state_features:
    ```json
    {
        "vehicle": {"vehicle_id": 1, "status": "AVAILABLE"},
        "order": {"order_id": 100, "priority": 1},
        "time": {"hour": 10, "is_peak_hour": true},
        "environment": {"active_vehicles": 20}
    }
    ```
    """
    trainer = RLTrainingService(db)
    prediction = await trainer.get_model_prediction(
        state_features=state_features,
        model_version=model_version
    )
    
    return prediction


# ==================== í†µê³„ & ëª¨ë‹ˆí„°ë§ ====================

@router.get("/ml/statistics")
async def get_ml_statistics(
    days: int = Query(7, ge=1, le=90),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ML ì‹œìŠ¤í…œ í†µê³„
    
    **í•™ìŠµ ë°ì´í„°, ì‹¤í—˜, ëª¨ë¸ í˜„í™© í†µê³„**
    """
    from sqlalchemy import func
    from app.models.ml_training import DispatchTrainingData, RLRewardHistory
    
    since = datetime.utcnow() - timedelta(days=days)
    
    # í•™ìŠµ ë°ì´í„° í†µê³„
    total_training_data = db.query(func.count(DispatchTrainingData.id)).scalar()
    completed_episodes = db.query(func.count(DispatchTrainingData.id)).filter(
        DispatchTrainingData.done == True
    ).scalar()
    
    avg_reward = db.query(func.avg(DispatchTrainingData.reward)).filter(
        DispatchTrainingData.done == True,
        DispatchTrainingData.collected_at >= since
    ).scalar()
    
    # ì‹¤í—˜ í†µê³„
    total_experiments = db.query(func.count(MLExperiment.id)).scalar()
    completed_experiments = db.query(func.count(MLExperiment.id)).filter(
        MLExperiment.status == "completed"
    ).scalar()
    
    # ëª¨ë¸ í†µê³„
    total_models = db.query(func.count(ModelVersion.id)).scalar()
    deployed_models = db.query(func.count(ModelVersion.id)).filter(
        ModelVersion.status == "deployed"
    ).scalar()
    
    # ìµœê·¼ ë³´ìƒ ì¶”ì´
    recent_rewards = db.query(
        RLRewardHistory.timestamp,
        RLRewardHistory.total_reward
    ).filter(
        RLRewardHistory.timestamp >= since
    ).order_by(RLRewardHistory.timestamp.desc()).limit(100).all()
    
    reward_trend = [
        {
            "timestamp": r.timestamp.isoformat(),
            "reward": float(r.total_reward)
        }
        for r in recent_rewards
    ]
    
    return {
        "period_days": days,
        "training_data": {
            "total_samples": total_training_data or 0,
            "completed_episodes": completed_episodes or 0,
            "average_reward": float(avg_reward) if avg_reward else 0.0
        },
        "experiments": {
            "total": total_experiments or 0,
            "completed": completed_experiments or 0
        },
        "models": {
            "total": total_models or 0,
            "deployed": deployed_models or 0
        },
        "reward_trend": reward_trend
    }


# ==================== Phase 3: ML-based Rule Suggestions ====================

@router.post("/ml/suggest-rules")
async def suggest_dispatch_rules(
    days_back: int = Query(30, ge=7, le=365, description="ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜"),
    limit: int = Query(10, ge=1, le=50, description="ìµœëŒ€ ì œì•ˆ ê·œì¹™ ìˆ˜"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ğŸ¤– **Phase 3: ML ê¸°ë°˜ ë°°ì°¨ ê·œì¹™ ìë™ ì œì•ˆ**
    
    ê³¼ê±° ë°°ì°¨ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë°°ì°¨ ê·œì¹™ì„ ìë™ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    - **ì˜¨ë„ëŒ€ë³„ ì°¨ëŸ‰ í• ë‹¹ íŒ¨í„´**
    - **ê±°ë¦¬ ê¸°ë°˜ ì°¨ëŸ‰ ì„ íƒ íŒ¨í„´**
    - **ì‹œê°„ëŒ€ë³„ ë°°ì°¨ íŒ¨í„´**
    - **ì ì¬ìœ¨ ìµœì í™” íŒ¨í„´**
    - **ê³ ê°ë³„ ì„ í˜¸ ì°¨ëŸ‰ íŒ¨í„´**
    
    **Parameters:**
    - days_back: ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼)
    - limit: ìµœëŒ€ ì œì•ˆ ê·œì¹™ ìˆ˜ (ê¸°ë³¸ 10ê°œ)
    
    **Returns:**
    ì œì•ˆëœ ê·œì¹™ ëª©ë¡ê³¼ ê° ê·œì¹™ì˜ ì‹ ë¢°ë„, ì§€ì§€ë„, ì˜ˆìƒ ê°œì„  íš¨ê³¼
    """
    from app.services.ml_rule_suggestion_service import MLRuleSuggestionService
    
    service = MLRuleSuggestionService(db)
    suggestions = await service.analyze_and_suggest_rules(
        days_back=days_back,
        limit=limit
    )
    
    return {
        "analysis_period_days": days_back,
        "total_suggestions": len(suggestions),
        "suggestions": [
            {
                "rule_type": s.rule_type,
                "name": s.name,
                "description": s.description,
                "conditions": s.conditions,
                "actions": s.actions,
                "confidence": round(s.confidence, 3),
                "support": s.support,
                "expected_improvement": s.expected_improvement,
                "priority": s.priority
            }
            for s in suggestions
        ],
        "generated_at": datetime.utcnow().isoformat()
    }


@router.post("/ml/apply-suggested-rules")
async def apply_suggested_rules(
    days_back: int = Query(30, ge=7, le=365),
    limit: int = Query(10, ge=1, le=50),
    auto_activate: bool = Query(False, description="ìë™ í™œì„±í™” ì—¬ë¶€"),
    min_confidence: float = Query(0.7, ge=0.0, le=1.0, description="ìµœì†Œ ì‹ ë¢°ë„"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ğŸš€ **MLì´ ì œì•ˆí•œ ê·œì¹™ì„ ì‹¤ì œ ì‹œìŠ¤í…œì— ì ìš©**
    
    ì œì•ˆëœ ê·œì¹™ ì¤‘ ì‹ ë¢°ë„ê°€ ë†’ì€ ê·œì¹™ë“¤ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤.
    
    **Parameters:**
    - days_back: ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜
    - limit: ìµœëŒ€ ì ìš© ê·œì¹™ ìˆ˜
    - auto_activate: ìƒì„± ì¦‰ì‹œ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸: False)
    - min_confidence: ì ìš©í•  ê·œì¹™ì˜ ìµœì†Œ ì‹ ë¢°ë„ (ê¸°ë³¸: 0.7)
    
    **Returns:**
    ìƒì„±ëœ ê·œì¹™ ëª©ë¡ê³¼ ID
    """
    from app.services.ml_rule_suggestion_service import MLRuleSuggestionService
    
    service = MLRuleSuggestionService(db)
    
    # 1. ê·œì¹™ ì œì•ˆ ë°›ê¸°
    suggestions = await service.analyze_and_suggest_rules(
        days_back=days_back,
        limit=limit
    )
    
    # 2. ì‹ ë¢°ë„ í•„í„°ë§
    filtered_suggestions = [
        s for s in suggestions
        if s.confidence >= min_confidence
    ]
    
    # 3. ê·œì¹™ ìƒì„±
    created_rules = await service.create_rules_from_suggestions(
        suggestions=filtered_suggestions,
        auto_activate=auto_activate
    )
    
    return {
        "success": True,
        "total_suggestions": len(suggestions),
        "filtered_by_confidence": len(filtered_suggestions),
        "created_rules": len(created_rules),
        "auto_activated": auto_activate,
        "rules": [
            {
                "id": rule.id,
                "name": rule.name,
                "rule_type": rule.rule_type,
                "priority": rule.priority,
                "is_active": rule.is_active,
                "created_at": rule.created_at.isoformat()
            }
            for rule in created_rules
        ]
    }


@router.get("/ml/rule-performance/{rule_id}")
async def get_rule_performance(
    rule_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    ğŸ“Š **ê·œì¹™ ì„±ëŠ¥ ë¦¬í¬íŠ¸**
    
    íŠ¹ì • ê·œì¹™ì˜ ì‹¤í–‰ í†µê³„ì™€ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    **Returns:**
    - ì´ ì‹¤í–‰ íšŸìˆ˜
    - ì„±ê³µë¥ 
    - í‰ê·  ì‹¤í–‰ ì‹œê°„
    - ì´ ì ˆê° ê±°ë¦¬/ë¹„ìš©/ì‹œê°„
    """
    from app.services.ml_rule_suggestion_service import MLRuleSuggestionService
    
    service = MLRuleSuggestionService(db)
    report = await service.get_rule_performance_report(rule_id)
    
    return report


@router.post("/ml/auto-optimize")
async def auto_optimize_rules(
    days_back: int = Query(30, ge=7, le=365),
    optimization_target: str = Query("balanced", regex="^(distance|cost|time|balanced)$"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    âš¡ **ìë™ ìµœì í™” (í•œ ë²ˆì— ëª¨ë“  ì‘ì—… ì‹¤í–‰)**
    
    1. ê³¼ê±° ë°ì´í„° ë¶„ì„
    2. ê·œì¹™ ì œì•ˆ
    3. ê³ ì‹ ë¢°ë„ ê·œì¹™ ìë™ ìƒì„±
    4. ê¸°ì¡´ ê·œì¹™ ì„±ëŠ¥ í‰ê°€
    5. ì €ì„±ëŠ¥ ê·œì¹™ ë¹„í™œì„±í™”
    
    **Parameters:**
    - days_back: ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜
    - optimization_target: ìµœì í™” ëª©í‘œ (distance/cost/time/balanced)
    
    **Returns:**
    ìµœì í™” ê²°ê³¼ ìš”ì•½
    """
    from app.services.ml_rule_suggestion_service import MLRuleSuggestionService
    from app.models.dispatch_rule import DispatchRule, RuleExecutionLog
    
    service = MLRuleSuggestionService(db)
    
    # Step 1: ê·œì¹™ ì œì•ˆ
    suggestions = await service.analyze_and_suggest_rules(
        days_back=days_back,
        limit=20
    )
    
    # Step 2: ê³ ì‹ ë¢°ë„ ê·œì¹™ ìƒì„± (80% ì´ìƒ)
    high_confidence = [s for s in suggestions if s.confidence >= 0.8]
    created_rules = await service.create_rules_from_suggestions(
        suggestions=high_confidence,
        auto_activate=True
    )
    
    # Step 3: ê¸°ì¡´ ê·œì¹™ ì„±ëŠ¥ í‰ê°€
    existing_rules = db.query(DispatchRule).filter(
        DispatchRule.is_active == True
    ).all()
    
    poor_performing_rules = []
    for rule in existing_rules:
        if rule.execution_count >= 10:  # ìµœì†Œ 10íšŒ ì´ìƒ ì‹¤í–‰ëœ ê·œì¹™ë§Œ
            if rule.success_rate and rule.success_rate < 50:  # ì„±ê³µë¥  50% ë¯¸ë§Œ
                rule.is_active = False
                poor_performing_rules.append({
                    "id": rule.id,
                    "name": rule.name,
                    "success_rate": rule.success_rate
                })
    
    db.commit()
    
    return {
        "success": True,
        "optimization_target": optimization_target,
        "analysis_period_days": days_back,
        "summary": {
            "total_suggestions": len(suggestions),
            "high_confidence_suggestions": len(high_confidence),
            "rules_created": len(created_rules),
            "rules_deactivated": len(poor_performing_rules)
        },
        "created_rules": [
            {"id": r.id, "name": r.name, "priority": r.priority}
            for r in created_rules
        ],
        "deactivated_rules": poor_performing_rules,
        "next_review_date": (datetime.utcnow() + timedelta(days=7)).isoformat()
    }

