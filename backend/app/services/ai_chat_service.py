import logging
import json
import re
import time
from typing import Dict, Any, Optional, List
from datetime import datetime, date, timedelta
from sqlalchemy.orm import Session
import os

from app.models.order import Order
from app.models.client import Client
from app.models.ai_usage_log import AIUsageLog

logger = logging.getLogger(__name__)

# OpenAIëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# GeminiëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logger.warning("âš ï¸ Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


class AIChatService:
    """
    AI ì±„íŒ… ì„œë¹„ìŠ¤ - OpenAI GPT ë˜ëŠ” Google Geminië¥¼ ì‚¬ìš©í•œ ìì—°ì–´ ì²˜ë¦¬
    """
    
    def __init__(self, model_name: str = "auto"):
        """
        Args:
            model_name: "gpt-4", "gpt-3.5-turbo", "gemini-pro", "auto"
                       "auto"ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ ìë™ ì„ íƒ
        """
        self.model_name = model_name
        self.openai_client = None
        self.gemini_model = None
        
        # OpenAI ì„¤ì •
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key and OPENAI_AVAILABLE:
            self.openai_client = OpenAI(api_key=openai_key)
            logger.info("âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # Gemini ì„¤ì •
        gemini_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if gemini_key and GEMINI_AVAILABLE:
            genai.configure(api_key=gemini_key)
            self.gemini_model = genai.GenerativeModel('gemini-pro')
            logger.info("âœ… Gemini API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì„ íƒ ë¡œì§
        if model_name == "auto":
            if self.openai_client:
                self.model_name = "gpt-4"
                logger.info("ğŸ¤– ìë™ ì„ íƒ: GPT-4")
            elif self.gemini_model:
                self.model_name = "gemini-pro"
                logger.info("ğŸ¤– ìë™ ì„ íƒ: Gemini Pro")
            else:
                self.model_name = "simulation"
                logger.warning("âš ï¸ AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        
        logger.info(f"ğŸ¯ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸: {self.model_name}")
    
    async def process_message(
        self,
        message: str,
        context: Dict[str, Any],
        db: Session
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì˜ë„ íŒŒì•…
        
        Args:
            message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            {
                "intent": str,  # "create_order", "update_order", "query_order", etc.
                "message": str,  # AI ì‘ë‹µ ë©”ì‹œì§€
                "parsed_order": dict,  # ì¶”ì¶œëœ ì£¼ë¬¸ ì •ë³´
                "model_used": str  # ì‚¬ìš©ëœ AI ëª¨ë¸
            }
        """
        
        try:
            # ëª¨ë¸ë³„ ì²˜ë¦¬
            if self.model_name in ["gpt-4", "gpt-3.5-turbo"] and self.openai_client:
                result = await self._process_with_openai(message, context, db)
            elif self.model_name == "gemini-pro" and self.gemini_model:
                result = await self._process_with_gemini(message, context, db)
            else:
                # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (íŒ¨í„´ ë§¤ì¹­)
                result = await self._process_with_simulation(message, context, db)
            
            # ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´ ì¶”ê°€
            result["model_used"] = self.model_name
            return result
        
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "intent": "error",
                "message": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "parsed_order": None,
                "model_used": self.model_name
            }
    
    async def _process_with_openai(
        self,
        message: str,
        context: Dict[str, Any],
        db: Session
    ) -> Dict[str, Any]:
        """
        OpenAI GPTë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ ì²˜ë¦¬
        """
        
        start_time = time.time()
        usage_log = None
        
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt()
            
            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            recent_messages = context.get("recent_messages", [])
            accumulated_context = self._accumulate_context(message, recent_messages)
            user_prompt = self._build_user_prompt(accumulated_context, context)
            
            logger.info(f"ğŸ¤– OpenAI API í˜¸ì¶œ... (ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì)")
            
            # ëª¨ë¸ ì„ íƒ (ì‹¤ì œ GPT-4 ì‚¬ìš©)
            if self.model_name == "gpt-4":
                model = "gpt-4o"  # GPT-4 Omni (ìµœì‹ , ë¹ ë¦„, ì €ë ´)
            elif self.model_name == "gpt-3.5-turbo":
                model = "gpt-3.5-turbo"
            else:
                model = "gpt-4o"  # ê¸°ë³¸ê°’
            
            logger.info(f"ğŸ¯ ì‚¬ìš© ëª¨ë¸: {model}")
            
            # OpenAI API í˜¸ì¶œ (ìµœì‹  v1.0+ API)
            response = self.openai_client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ëœ ì‘ë‹µ
                max_tokens=2000,
                response_format={"type": "json_object"}  # JSON ì‘ë‹µ ê°•ì œ
            )
            
            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time_ms = int((time.time() - start_time) * 1000)
            
            # ì‘ë‹µ íŒŒì‹±
            ai_response = response.choices[0].message.content
            logger.info(f"âœ… OpenAI ì‘ë‹µ ë°›ìŒ: {len(ai_response)}ì (ì‘ë‹µ ì‹œê°„: {response_time_ms}ms)")
            
            # ì‚¬ìš©ëŸ‰ ì •ë³´ ì¶”ì¶œ
            usage = response.usage
            prompt_tokens = usage.prompt_tokens
            completion_tokens = usage.completion_tokens
            total_tokens = usage.total_tokens
            
            # ë¹„ìš© ê³„ì‚° (ëª¨ë¸ë³„ í† í°ë‹¹ ë¹„ìš©)
            prompt_cost, completion_cost = self._calculate_cost(model, prompt_tokens, completion_tokens)
            total_cost = prompt_cost + completion_cost
            
            logger.info(f"ğŸ’° ë¹„ìš©: ì…ë ¥ {prompt_tokens} í† í° (${prompt_cost:.4f}) + "
                       f"ì¶œë ¥ {completion_tokens} í† í° (${completion_cost:.4f}) = "
                       f"ì´ ${total_cost:.4f}")
            
            # JSON ì‘ë‹µ íŒŒì‹±
            result = json.loads(ai_response)
            
            # ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì €ì¥
            usage_log = AIUsageLog(
                user_id=context.get("user_id"),
                session_id=context.get("session_id"),
                model_name=model,
                provider="openai",
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens,
                prompt_cost=prompt_cost,
                completion_cost=completion_cost,
                total_cost=total_cost,
                response_time_ms=response_time_ms,
                status="success",
                intent=result.get("intent"),
                created_at=datetime.now()
            )
            db.add(usage_log)
            db.commit()
            logger.info(f"ğŸ’¾ ì‚¬ìš©ëŸ‰ ë¡œê·¸ ì €ì¥ ì™„ë£Œ (ID: {usage_log.id})")
            
            return result
        
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}, ì‘ë‹µ: {ai_response[:200]}")
            
            # ì—ëŸ¬ ë¡œê·¸ ì €ì¥
            if usage_log:
                usage_log.status = "error"
                usage_log.error_message = f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
                db.commit()
            
            # ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            return await self._process_with_simulation(message, context, db)
        
        except Exception as e:
            logger.error(f"OpenAI API ì˜¤ë¥˜: {e}")
            
            # ì—ëŸ¬ ë¡œê·¸ ì €ì¥
            response_time_ms = int((time.time() - start_time) * 1000)
            error_log = AIUsageLog(
                user_id=context.get("user_id"),
                session_id=context.get("session_id"),
                model_name=model if 'model' in locals() else self.model_name,
                provider="openai",
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0,
                prompt_cost=0.0,
                completion_cost=0.0,
                total_cost=0.0,
                response_time_ms=response_time_ms,
                status="error",
                error_message=str(e),
                created_at=datetime.now()
            )
            db.add(error_log)
            db.commit()
            
            # ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            return await self._process_with_simulation(message, context, db)
    
    async def _process_with_gemini(
        self,
        message: str,
        context: Dict[str, Any],
        db: Session
    ) -> Dict[str, Any]:
        """
        Google Geminië¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ ì²˜ë¦¬
        """
        
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt()
            
            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            recent_messages = context.get("recent_messages", [])
            accumulated_context = self._accumulate_context(message, recent_messages)
            user_prompt = self._build_user_prompt(accumulated_context, context)
            
            # Geminiìš© ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"""{system_prompt}

===== ì‚¬ìš©ì ë©”ì‹œì§€ =====
{user_prompt}

===== ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì‘ë‹µ) =====
{{
  "intent": "create_order | create_multiple_orders | update_order | query_order | unknown",
  "message": "ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µ ë©”ì‹œì§€",
  "parsed_order": {{"temperature_zone": "ëƒ‰ë™", "pickup_address": "ì„œìš¸", ...}},
  "parsed_orders": [...],
  "action": "confirm_order | waiting_confirmation | ..."
}}"""
            
            logger.info(f"ğŸ¤– Gemini API í˜¸ì¶œ... (ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì)")
            
            # Gemini API í˜¸ì¶œ
            response = self.gemini_model.generate_content(
                full_prompt,
                generation_config={
                    "temperature": 0.3,
                    "max_output_tokens": 2048,
                }
            )
            
            # ì‘ë‹µ íŒŒì‹±
            ai_response = response.text
            logger.info(f"âœ… Gemini ì‘ë‹µ ë°›ìŒ: {len(ai_response)}ì")
            
            # JSON ì¶”ì¶œ (GeminiëŠ” ë•Œë•Œë¡œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ìŒˆ)
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # ì¼ë°˜ JSON ì°¾ê¸°
                json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = ai_response
            
            # JSON íŒŒì‹±
            result = json.loads(json_str)
            
            return result
        
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}, ì‘ë‹µ: {ai_response[:200] if 'ai_response' in locals() else 'N/A'}")
            # ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            return await self._process_with_simulation(message, context, db)
        except Exception as e:
            logger.error(f"Gemini API ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ í´ë°±
            return await self._process_with_simulation(message, context, db)
    
    async def _process_with_simulation(
        self,
        message: str,
        context: Dict[str, Any],
        db: Session
    ) -> Dict[str, Any]:
        """
        ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©
        """
        
        message_lower = message.lower()
        
        # ìµœê·¼ ë©”ì‹œì§€ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        recent_messages = context.get("recent_messages", [])
        accumulated_context = self._accumulate_context(message, recent_messages)
        accumulated_lower = accumulated_context.lower()
        
        # ì£¼ë¬¸ ìƒì„± íŒ¨í„´ (ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰)
        # íŒ”ë ˆíŠ¸ ì •ë³´ê°€ ìˆê±°ë‚˜, ë°°ì†¡ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì£¼ë¬¸ ìƒì„± ì‹œë„
        has_order_keywords = any(keyword in accumulated_lower for keyword in ['ë³´ë‚´', 'ë°°ì†¡', 'ì£¼ë¬¸', 'ë“±ë¡', 'ì¶œë°œ'])
        has_pallet_info = 'íŒ”ë ˆíŠ¸' in accumulated_lower
        has_temp_zone = any(temp in accumulated_lower for temp in ['ëƒ‰ë™', 'ëƒ‰ì¥', 'ìƒì˜¨'])
        
        if has_order_keywords or (has_pallet_info and has_temp_zone):
            # 1:N ë°°ì†¡ íŒ¨í„´ ì²´í¬ (ì—¬ëŸ¬ í•˜ì°¨ì§€) - ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            parsed_orders = self._extract_multiple_orders_simulation(accumulated_context, db)
            
            if parsed_orders and len(parsed_orders) > 1:
                # ì—¬ëŸ¬ ì£¼ë¬¸ ìƒì„±
                summary = self._format_multiple_orders_summary(parsed_orders)
                
                # ë°°ì°¨ ì¶”ì²œ ë©”ì‹œì§€ ì¶”ê°€
                dispatch_recommendation = parsed_orders[0].get('_dispatch_recommendation') if parsed_orders else None
                recommendation_msg = ""
                if dispatch_recommendation and dispatch_recommendation.get('needs_split'):
                    recommendation_msg = dispatch_recommendation.get('message', '')
                
                return {
                    "intent": "create_multiple_orders",
                    "message": f"ë‹¤ìŒ {len(parsed_orders)}ê°œ ì£¼ë¬¸ì„ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n\n{summary}{recommendation_msg}\n\në“±ë¡í•˜ì‹œë ¤ë©´ 'ë„¤' ë˜ëŠ” 'í™•ì¸'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    "parsed_orders": parsed_orders,
                    "parsed_order": None,
                    "dispatch_recommendation": dispatch_recommendation
                }
            else:
                # ë‹¨ì¼ ì£¼ë¬¸ - ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
                parsed_order = parsed_orders[0] if parsed_orders else self._extract_order_info_simulation(accumulated_context, db)
                
                if parsed_order and self._validate_order_info(parsed_order):
                    # ì£¼ë¬¸ ì •ë³´ ìš”ì•½
                    summary = self._format_order_summary(parsed_order)
                    
                    return {
                        "intent": "create_order",
                        "message": f"ë‹¤ìŒ ì •ë³´ë¡œ ì£¼ë¬¸ì„ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n\n{summary}\n\në“±ë¡í•˜ì‹œë ¤ë©´ 'ë„¤' ë˜ëŠ” 'í™•ì¸'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                        "parsed_order": parsed_order
                    }
                else:
                    return {
                        "intent": "need_more_info",
                        "message": "ì£¼ë¬¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:\nâ€¢ ì˜¨ë„ëŒ€ (ëƒ‰ë™/ëƒ‰ì¥/ìƒì˜¨)\nâ€¢ ìƒì°¨ì§€ ë˜ëŠ” í•˜ì°¨ì§€\nâ€¢ íŒ”ë ˆíŠ¸ ìˆ˜\n\n**1:N ë°°ì†¡ ì˜ˆì‹œ:**\n'ì„œìš¸ì—ì„œ ë¶€ì‚° 10íŒ”ë ˆíŠ¸, ëŒ€êµ¬ 15íŒ”ë ˆíŠ¸, ê´‘ì£¼ 8íŒ”ë ˆíŠ¸ ëƒ‰ë™'",
                        "parsed_order": parsed_order
                    }
        
        # ì£¼ë¬¸ ìˆ˜ì • íŒ¨í„´
        if any(keyword in message_lower for keyword in ['ìˆ˜ì •', 'ë³€ê²½', 'ë°”ê¿”']):
            return {
                "intent": "update_order",
                "message": "ì£¼ë¬¸ ìˆ˜ì • ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì£¼ë¬¸ë²ˆí˜¸ì™€ ë³€ê²½í•  ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
                "parsed_order": None
            }
        
        # ì£¼ë¬¸ ì¡°íšŒ íŒ¨í„´
        if any(keyword in message_lower for keyword in ['ì¡°íšŒ', 'í™•ì¸', 'ì°¾ì•„', 'ê²€ìƒ‰']):
            return {
                "intent": "query_order",
                "message": "ì£¼ë¬¸ ì¡°íšŒ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì£¼ë¬¸ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                "parsed_order": None
            }
        
        # ê¸°íƒ€
        return {
            "intent": "unknown",
            "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n**ë‹¨ì¼ ë°°ì†¡:**\n'ì„œìš¸ì—ì„œ ë¶€ì‚°ìœ¼ë¡œ ëƒ‰ë™ 10íŒ”ë ˆíŠ¸ 500kg ë³´ë‚´ì¤˜'\n\n**1:N ë°°ì†¡ (ì—¬ëŸ¬ ê³³ìœ¼ë¡œ):**\n'ì„œìš¸ ì°½ê³ ì—ì„œ ì¶œë°œ\n- ë¶€ì‚°: ëƒ‰ë™ 10íŒ”ë ˆíŠ¸\n- ëŒ€ì „: ëƒ‰ë™ 15íŒ”ë ˆíŠ¸\n- ê´‘ì£¼: ëƒ‰ì¥ 5íŒ”ë ˆíŠ¸'",
            "parsed_order": None
        }
    
    def _extract_order_info_simulation(self, message: str, db: Session) -> Dict[str, Any]:
        """
        ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œ ì£¼ë¬¸ ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ ì •ê·œì‹)
        """
        
        order_info = {}
        
        # ì˜¨ë„ëŒ€ ì¶”ì¶œ
        if 'ëƒ‰ë™' in message:
            order_info['temperature_zone'] = 'ëƒ‰ë™'
        elif 'ëƒ‰ì¥' in message:
            order_info['temperature_zone'] = 'ëƒ‰ì¥'
        elif 'ìƒì˜¨' in message:
            order_info['temperature_zone'] = 'ìƒì˜¨'
        
        # íŒ”ë ˆíŠ¸ ìˆ˜ ì¶”ì¶œ (p ì•½ì–´ ì§€ì›)
        pallet_match = re.search(r'(\d+)\s*(?:íŒ”ë ˆíŠ¸|p(?:allet)?)', message, re.IGNORECASE)
        if pallet_match:
            order_info['pallet_count'] = int(pallet_match.group(1))
        
        # ì¤‘ëŸ‰, ë¶€í”¼ëŠ” ì¶”ì¶œí•˜ì§€ ì•ŠìŒ
        
        # ìƒì°¨ì§€/í•˜ì°¨ì§€ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
        # "ì„œìš¸ì—ì„œ ë¶€ì‚°ìœ¼ë¡œ" íŒ¨í„´
        location_match = re.search(r'([ê°€-í£]+)ì—ì„œ\s*([ê°€-í£]+)(?:ìœ¼ë¡œ|ë¡œ)', message)
        if location_match:
            order_info['pickup_address'] = location_match.group(1)
            order_info['delivery_address'] = location_match.group(2)
        
        # ì‹œê°„ ì¶”ì¶œ (ì˜ˆ: "ì˜¤ì „ 9ì‹œ", "14ì‹œ")
        time_patterns = [
            (r'ì˜¤ì „\s*(\d+)ì‹œ', 'morning'),
            (r'ì˜¤í›„\s*(\d+)ì‹œ', 'afternoon'),
            (r'(\d+)ì‹œ', 'hour')
        ]
        
        for pattern, time_type in time_patterns:
            matches = list(re.finditer(pattern, message))
            for idx, match in enumerate(matches):
                hour = int(match.group(1))
                
                # ì˜¤í›„ ì‹œê°„ ë³€í™˜
                if time_type == 'afternoon' and hour < 12:
                    hour += 12
                
                time_str = f"{hour:02d}:00"
                
                # ì²« ë²ˆì§¸ ì‹œê°„ì€ ìƒì°¨, ë‘ ë²ˆì§¸ëŠ” í•˜ì°¨ë¡œ ì¶”ì •
                if idx == 0 or 'ìƒì°¨' in message[:match.start()]:
                    order_info['pickup_start_time'] = time_str
                else:
                    order_info['delivery_start_time'] = time_str
        
        # ë‚ ì§œ ì¶”ì¶œ (ì˜ˆ: "ë‚´ì¼", "ì˜¤ëŠ˜", "2024-02-05")
        if 'ë‚´ì¼' in message:
            order_info['order_date'] = (date.today() + timedelta(days=1)).isoformat()
        elif 'ì˜¤ëŠ˜' in message or 'ë‹¹ì¼' in message:
            order_info['order_date'] = date.today().isoformat()
        
        logger.info(f"ì¶”ì¶œëœ ì£¼ë¬¸ ì •ë³´: {order_info}")
        return order_info
    
    def _extract_multiple_orders_simulation(self, message: str, db: Session) -> List[Dict[str, Any]]:
        """
        1:N ë°°ì†¡ íŒ¨í„´ì—ì„œ ì—¬ëŸ¬ ì£¼ë¬¸ ì •ë³´ ì¶”ì¶œ
        
        ìë™ 1:N ì¸ì‹ íŒ¨í„´:
        1. "ì„œìš¸ì—ì„œ ë¶€ì‚°, ëŒ€êµ¬, ê´‘ì£¼" â†’ ìƒì°¨ì§€ 1ê³³ + í•˜ì°¨ì§€ ì—¬ëŸ¬ ê³³
        2. "ì„œìš¸ ì°½ê³ ì—ì„œ ë¶€ì‚°ì  10íŒ”ë ˆíŠ¸, ëŒ€êµ¬ì  15íŒ”ë ˆíŠ¸"
        3. "ì„œìš¸ì—ì„œ ì¶œë°œ - ë¶€ì‚°: 10íŒ”ë ˆíŠ¸ - ëŒ€êµ¬: 15íŒ”ë ˆíŠ¸"
        """
        
        orders = []
        
        # ìƒì°¨ì§€ ì¶”ì¶œ (ë” ìœ ì—°í•œ íŒ¨í„´)
        pickup_patterns = [
            r'([ê°€-í£\s]+)(?:ì°½ê³ |ì„¼í„°|ë¬¼ë¥˜|ì )?(?:ì—ì„œ|ì„œ)\s*(?:ì¶œë°œ|ì‹œì‘|ë‚˜ê°€)',
            r'([ê°€-í£\s]+)(?:ì°½ê³ |ì„¼í„°)?ì—ì„œ\s+([ê°€-í£\s,]+)\s*(?:ë¡œ|ìœ¼ë¡œ|ë°°ì†¡|ë³´ë‚´)',
        ]
        
        pickup_address = None
        for pattern in pickup_patterns:
            match = re.search(pattern, message)
            if match:
                pickup_address = match.group(1).strip()
                break
        
        if not pickup_address:
            # ë‹¨ì¼ ì£¼ë¬¸ìœ¼ë¡œ ì²˜ë¦¬
            return [self._extract_order_info_simulation(message, db)]
        
        logger.info(f"ğŸšš ìƒì°¨ì§€ ê°ì§€: {pickup_address}")
        logger.info(f"ğŸ” í•˜ì°¨ì§€ ì¶”ì¶œ ì‹œì‘... (ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì)")
        
        # í•˜ì°¨ì§€ë³„ ì •ë³´ ì¶”ì¶œ íŒ¨í„´ (ë” ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        delivery_patterns = [
            # "ë¶€ì‚° 10p, ëŒ€êµ¬ 15p" (p = íŒ”ë ˆíŠ¸ ì•½ì–´)
            r'([ê°€-í£]+(?:ì |ì°½ê³ |ì„¼í„°)?)\s+(\d+)\s*p(?:allet)?',
            # "ë¶€ì‚° 10íŒ”ë ˆíŠ¸, ëŒ€êµ¬ 15íŒ”ë ˆíŠ¸" (ì‰¼í‘œ êµ¬ë¶„, ê°€ì¥ ì¼ë°˜ì )
            r'([ê°€-í£]+(?:ì |ì°½ê³ |ì„¼í„°)?)\s+(\d+)\s*íŒ”ë ˆíŠ¸',
            # "ë¶€ì‚° 10íŒ”ë ˆíŠ¸ 500kg" (ì¤‘ëŸ‰ í¬í•¨)
            r'([ê°€-í£]+(?:ì |ì°½ê³ |ì„¼í„°)?)\s+(\d+)\s*íŒ”ë ˆíŠ¸\s*(\d+(?:\.\d+)?)\s*kg',
            # "- ë¶€ì‚°ì : ëƒ‰ë™ 10íŒ”ë ˆíŠ¸ 500kg"
            r'[-â€¢]\s*([ê°€-í£\s]+[ê°€-í£ì ])\s*[:ï¼š]?\s*(ëƒ‰ë™|ëƒ‰ì¥|ìƒì˜¨)?\s*(\d+)\s*íŒ”ë ˆíŠ¸\s*(\d+(?:\.\d+)?)\s*kg',
            # "1. ë¶€ì‚°ì  10íŒ”ë ˆíŠ¸ 500kg"
            r'\d+\.\s*([ê°€-í£\s]+(?:ì |ì°½ê³ |ì„¼í„°)?)\s+(\d+)\s*íŒ”ë ˆíŠ¸(?:\s*(\d+(?:\.\d+)?)\s*kg)?',
        ]
        
        # ì˜¨ë„ëŒ€ ì¶”ì¶œ (ì „ì²´ ë©”ì‹œì§€ì—ì„œ)
        temperature_zone = None
        if 'ëƒ‰ë™' in message:
            temperature_zone = 'ëƒ‰ë™'
        elif 'ëƒ‰ì¥' in message:
            temperature_zone = 'ëƒ‰ì¥'
        elif 'ìƒì˜¨' in message:
            temperature_zone = 'ìƒì˜¨'
        
        # í•˜ì°¨ì§€ ì¶”ì¶œ
        found_orders = []
        for pattern in delivery_patterns:
            matches = re.finditer(pattern, message)
            for match in matches:
                groups = match.groups()
                
                # íŒ¨í„´ì— ë”°ë¼ íŒŒì‹±
                delivery_address = None
                pallet_count = None
                temp_zone = temperature_zone
                
                if len(groups) == 2:  # íŒ¨í„´ 1: "ë¶€ì‚° 10íŒ”ë ˆíŠ¸"
                    delivery_address = groups[0].strip()
                    pallet_count = int(groups[1])
                    
                elif len(groups) == 3:
                    # íŒ¨í„´ 2: "ë¶€ì‚° 10íŒ”ë ˆíŠ¸ 500kg" ë˜ëŠ” íŒ¨í„´ 4: "1. ë¶€ì‚° 10íŒ”ë ˆíŠ¸"
                    delivery_address = groups[0].strip()
                    pallet_count = int(groups[1])
                    # ì¤‘ëŸ‰ì€ ë¬´ì‹œ
                        
                elif len(groups) == 4:  # íŒ¨í„´ 3: "- ë¶€ì‚°ì : ëƒ‰ë™ 10íŒ”ë ˆíŠ¸ 500kg"
                    delivery_address = groups[0].strip()
                    temp_zone = groups[1] or temperature_zone
                    pallet_count = int(groups[2])
                    # ì¤‘ëŸ‰ì€ ë¬´ì‹œ
                
                if delivery_address and pallet_count:
                    order_info = {
                        'pickup_address': pickup_address,
                        'delivery_address': delivery_address,
                        'pallet_count': pallet_count
                    }
                    
                    if temp_zone:
                        order_info['temperature_zone'] = temp_zone
                    
                    # ì¤‘ë³µ ì²´í¬ (ê°™ì€ í•˜ì°¨ì§€ëŠ” í•œ ë²ˆë§Œ)
                    if not any(o['delivery_address'] == delivery_address for o in found_orders):
                        found_orders.append(order_info)
                        logger.info(f"  ğŸ“¦ í•˜ì°¨ì§€ {len(found_orders)}: {delivery_address} - {pallet_count}íŒ”ë ˆíŠ¸")
        
        if not found_orders:
            logger.warning(f"âš ï¸ í•˜ì°¨ì§€ ì¶”ì¶œ ì‹¤íŒ¨. íŒ¨í„´ ë§¤ì¹­ ì•ˆ ë¨. ë©”ì‹œì§€ ìƒ˜í”Œ: '{message[:100]}'")
        
        orders = found_orders
        
        # ë‚ ì§œ ì¶”ì¶œ (ëª¨ë“  ì£¼ë¬¸ì— ì ìš©)
        order_date = None
        if 'ë‚´ì¼' in message:
            order_date = (date.today() + timedelta(days=1)).isoformat()
        elif 'ì˜¤ëŠ˜' in message or 'ë‹¹ì¼' in message:
            order_date = date.today().isoformat()
        
        if order_date:
            for order in orders:
                order['order_date'] = order_date
        
        # íŒ”ë ˆíŠ¸ ì´ˆê³¼ ì²´í¬ ë° N:N ë°°ì°¨ ì¶”ì²œ
        if orders:
            total_pallets = sum(order.get('pallet_count', 0) for order in orders)
            logger.info(f"ğŸ“Š ì´ íŒ”ë ˆíŠ¸: {total_pallets}ê°œ")
            
            # ëŒ€ê¸° ì¤‘ ì°¨ëŸ‰ ì¡°íšŒ
            available_vehicles = self._get_available_vehicles(db)
            if available_vehicles and total_pallets > 0:
                # N:N ë°°ì°¨ ì¶”ì²œ í•„ìš” ì—¬ë¶€ ì²´í¬
                dispatch_recommendation = self._recommend_dispatch(orders, available_vehicles, db)
                if dispatch_recommendation:
                    # ë°°ì°¨ ì¶”ì²œ ì •ë³´ë¥¼ ì£¼ë¬¸ì— ì²¨ë¶€
                    for order in orders:
                        order['_dispatch_recommendation'] = dispatch_recommendation
        
        logger.info(f"ì¶”ì¶œëœ {len(orders)}ê°œ ì£¼ë¬¸: {orders}")
        return orders if orders else [self._extract_order_info_simulation(message, db)]
    
    def _format_multiple_orders_summary(self, orders: List[Dict[str, Any]]) -> str:
        """
        ì—¬ëŸ¬ ì£¼ë¬¸ ì •ë³´ ìš”ì•½ í¬ë§·íŒ…
        """
        lines = []
        
        for idx, order in enumerate(orders, 1):
            lines.append(f"ğŸ“¦ **ì£¼ë¬¸ {idx}**")
            
            if 'pickup_address' in order:
                lines.append(f"  â€¢ ìƒì°¨ì§€: {order['pickup_address']}")
            
            if 'delivery_address' in order:
                lines.append(f"  â€¢ í•˜ì°¨ì§€: {order['delivery_address']}")
            
            if 'temperature_zone' in order:
                lines.append(f"  â€¢ ì˜¨ë„ëŒ€: {order['temperature_zone']}")
            
            if 'pallet_count' in order:
                lines.append(f"  â€¢ íŒ”ë ˆíŠ¸: {order['pallet_count']}ê°œ")
            
            # ì¤‘ëŸ‰ì€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            
            lines.append("")  # ë¹ˆ ì¤„
        
        return '\n'.join(lines)
    
    def _accumulate_context(self, current_message: str, recent_messages: List[Dict[str, Any]]) -> str:
        """
        ìµœê·¼ ëŒ€í™” ê¸°ë¡ì„ ëˆ„ì í•´ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        
        Args:
            current_message: í˜„ì¬ ë©”ì‹œì§€
            recent_messages: ìµœê·¼ ëŒ€í™” ê¸°ë¡ [{"role": "user/assistant", "content": "..."}]
        
        Returns:
            ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        context_parts = []
        
        # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (ë„ˆë¬´ ë§ìœ¼ë©´ í˜¼ë€)
        for msg in recent_messages[-5:]:
            if msg.get("role") == "user":
                context_parts.append(msg.get("content", ""))
        
        # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
        context_parts.append(current_message)
        
        # ê³µë°±ìœ¼ë¡œ ì—°ê²°
        accumulated = " ".join(context_parts)
        
        logger.info(f"ğŸ“ ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸: {accumulated[:200]}...")
        
        return accumulated
    
    def _validate_order_info(self, order_info: Dict[str, Any]) -> bool:
        """
        ì£¼ë¬¸ ì •ë³´ ìœ íš¨ì„± ê²€ì¦
        """
        # í•„ìˆ˜ í•„ë“œ: ì˜¨ë„ëŒ€, (ìƒì°¨ì§€ ë˜ëŠ” í•˜ì°¨ì§€), íŒ”ë ˆíŠ¸
        has_temperature = 'temperature_zone' in order_info
        has_location = 'pickup_address' in order_info or 'delivery_address' in order_info
        has_pallet = 'pallet_count' in order_info  # ì¤‘ëŸ‰ì€ ì„ íƒ ì‚¬í•­
        
        return has_temperature and has_location and has_pallet
    
    def _format_order_summary(self, order_info: Dict[str, Any]) -> str:
        """
        ì£¼ë¬¸ ì •ë³´ ìš”ì•½ í¬ë§·íŒ…
        """
        lines = []
        
        if 'temperature_zone' in order_info:
            lines.append(f"â€¢ ì˜¨ë„ëŒ€: {order_info['temperature_zone']}")
        
        if 'pickup_address' in order_info:
            lines.append(f"â€¢ ìƒì°¨ì§€: {order_info['pickup_address']}")
        
        if 'delivery_address' in order_info:
            lines.append(f"â€¢ í•˜ì°¨ì§€: {order_info['delivery_address']}")
        
        if 'pallet_count' in order_info:
            lines.append(f"â€¢ íŒ”ë ˆíŠ¸: {order_info['pallet_count']}ê°œ")
        
        # ì¤‘ëŸ‰, ë¶€í”¼ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
        
        if 'pickup_start_time' in order_info:
            lines.append(f"â€¢ ìƒì°¨ì‹œê°„: {order_info['pickup_start_time']}")
        
        if 'delivery_start_time' in order_info:
            lines.append(f"â€¢ í•˜ì°¨ì‹œê°„: {order_info['delivery_start_time']}")
        
        if 'order_date' in order_info:
            lines.append(f"â€¢ ì£¼ë¬¸ì¼ì: {order_info['order_date']}")
        
        return '\n'.join(lines)
    
    def _get_available_vehicles(self, db: Session) -> List[Dict[str, Any]]:
        """
        ëŒ€ê¸° ì¤‘ì¸ ì°¨ëŸ‰ ì¡°íšŒ
        
        Returns:
            [{"code": "V001", "max_pallets": 20, "status": "AVAILABLE"}, ...]
        """
        try:
            from app.models.vehicle import Vehicle
            
            # ëŒ€ê¸° ì¤‘ ì°¨ëŸ‰ ì¡°íšŒ (ìƒíƒœê°€ AVAILABLE ë˜ëŠ” IDLE)
            vehicles = db.query(Vehicle).filter(
                Vehicle.is_active == True,
                Vehicle.status.in_(['AVAILABLE', 'IDLE', 'available', 'idle'])
            ).all()
            
            result = []
            for vehicle in vehicles:
                result.append({
                    'code': vehicle.code,
                    'plate_number': vehicle.plate_number,
                    'max_pallets': vehicle.max_pallets or 20,  # ê¸°ë³¸ê°’ 20
                    'max_weight_kg': vehicle.max_weight_kg or 1000,  # ê¸°ë³¸ê°’ 1í†¤
                    'status': vehicle.status
                })
            
            logger.info(f"ğŸš› ëŒ€ê¸° ì¤‘ ì°¨ëŸ‰: {len(result)}ëŒ€")
            return result
        except Exception as e:
            logger.error(f"ì°¨ëŸ‰ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def _recommend_dispatch(
        self, 
        orders: List[Dict[str, Any]], 
        vehicles: List[Dict[str, Any]],
        db: Session
    ) -> Optional[Dict[str, Any]]:
        """
        N:N ë°°ì°¨ ì¶”ì²œ
        
        Args:
            orders: ì£¼ë¬¸ ë¦¬ìŠ¤íŠ¸
            vehicles: ëŒ€ê¸° ì¤‘ ì°¨ëŸ‰ ë¦¬ìŠ¤íŠ¸
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            {
                "needs_split": bool,  # ë¶„í•  í•„ìš” ì—¬ë¶€
                "total_pallets": int,
                "vehicle_assignments": [
                    {
                        "vehicle_code": "V001",
                        "assigned_orders": [0, 1, 2],  # ì£¼ë¬¸ ì¸ë±ìŠ¤
                        "total_pallets": 15,
                        "estimated_distance_km": 120.5,
                        "estimated_duration_min": 180
                    },
                    ...
                ],
                "message": str  # ì¶”ì²œ ë©”ì‹œì§€
            }
        """
        
        if not orders or not vehicles:
            return None
        
        total_pallets = sum(order.get('pallet_count', 0) for order in orders)
        
        # ë‹¨ì¼ ì°¨ëŸ‰ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•œì§€ ì²´í¬
        max_vehicle_capacity = max(v['max_pallets'] for v in vehicles)
        
        if total_pallets <= max_vehicle_capacity:
            # ë‹¨ì¼ ì°¨ëŸ‰ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
            logger.info(f"âœ… ë‹¨ì¼ ì°¨ëŸ‰ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥: {total_pallets}íŒ”ë ˆíŠ¸ <= {max_vehicle_capacity}íŒ”ë ˆíŠ¸")
            return None
        
        # N:N ë°°ì°¨ í•„ìš”
        logger.info(f"âš ï¸ N:N ë°°ì°¨ í•„ìš”: {total_pallets}íŒ”ë ˆíŠ¸ > {max_vehicle_capacity}íŒ”ë ˆíŠ¸")
        
        # ê°„ë‹¨í•œ First-Fit ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì°¨ëŸ‰ í• ë‹¹
        vehicle_assignments = []
        current_vehicle_idx = 0
        current_pallets = 0
        current_orders = []
        
        for idx, order in enumerate(orders):
            order_pallets = order.get('pallet_count', 0)
            
            # í˜„ì¬ ì°¨ëŸ‰ì— ì¶”ê°€ ê°€ëŠ¥í•œì§€ ì²´í¬
            if current_vehicle_idx < len(vehicles):
                vehicle_capacity = vehicles[current_vehicle_idx]['max_pallets']
                
                if current_pallets + order_pallets <= vehicle_capacity:
                    # í˜„ì¬ ì°¨ëŸ‰ì— ì¶”ê°€
                    current_pallets += order_pallets
                    current_orders.append(idx)
                else:
                    # í˜„ì¬ ì°¨ëŸ‰ ë§ˆë¬´ë¦¬í•˜ê³  ë‹¤ìŒ ì°¨ëŸ‰ìœ¼ë¡œ
                    if current_orders:
                        vehicle_assignments.append({
                            'vehicle_code': vehicles[current_vehicle_idx]['code'],
                            'plate_number': vehicles[current_vehicle_idx]['plate_number'],
                            'assigned_orders': current_orders.copy(),
                            'total_pallets': current_pallets
                        })
                    
                    # ë‹¤ìŒ ì°¨ëŸ‰
                    current_vehicle_idx += 1
                    if current_vehicle_idx < len(vehicles):
                        current_pallets = order_pallets
                        current_orders = [idx]
                    else:
                        # ì°¨ëŸ‰ ë¶€ì¡±
                        logger.warning(f"âš ï¸ ì°¨ëŸ‰ ë¶€ì¡±: {len(vehicles)}ëŒ€ë¡œ {len(orders)}ê±´ ì²˜ë¦¬ ë¶ˆê°€")
                        break
        
        # ë§ˆì§€ë§‰ ì°¨ëŸ‰ ì¶”ê°€
        if current_orders and current_vehicle_idx < len(vehicles):
            vehicle_assignments.append({
                'vehicle_code': vehicles[current_vehicle_idx]['code'],
                'plate_number': vehicles[current_vehicle_idx]['plate_number'],
                'assigned_orders': current_orders.copy(),
                'total_pallets': current_pallets
            })
        
        if not vehicle_assignments:
            return None
        
        # ì¶”ì²œ ë©”ì‹œì§€ ìƒì„±
        message_lines = [
            f"\nğŸš› **ìŠ¤ë§ˆíŠ¸ ë°°ì°¨ ì¶”ì²œ**",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ì´ {total_pallets}íŒ”ë ˆíŠ¸ë¥¼ {len(vehicle_assignments)}ëŒ€ ì°¨ëŸ‰ì— ë¶„í•  ë°°ì •",
            ""
        ]
        
        for idx, assignment in enumerate(vehicle_assignments, 1):
            assigned_order_indices = assignment['assigned_orders']
            assigned_orders_info = [orders[i] for i in assigned_order_indices]
            destinations = ", ".join([o.get('delivery_address', '?') for o in assigned_orders_info])
            
            message_lines.append(
                f"ğŸšš **ì°¨ëŸ‰ {idx}**: {assignment['vehicle_code']} ({assignment['plate_number']})"
            )
            message_lines.append(f"   â€¢ íŒ”ë ˆíŠ¸: {assignment['total_pallets']}ê°œ")
            message_lines.append(f"   â€¢ í•˜ì°¨ì§€: {destinations}")
            message_lines.append("")
        
        return {
            'needs_split': True,
            'total_pallets': total_pallets,
            'vehicle_count': len(vehicle_assignments),
            'vehicle_assignments': vehicle_assignments,
            'message': '\n'.join(message_lines)
        }
    
    def _build_system_prompt(self) -> str:
        """
        OpenAI GPTë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        return """ë‹¹ì‹ ì€ ë¬¼ë¥˜ ì£¼ë¬¸ ê´€ë¦¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì£¼ë¬¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.

**ì£¼ë¬¸ ì •ë³´ í•„ë“œ:**
- order_date: ì£¼ë¬¸ ë‚ ì§œ (YYYY-MM-DD)
- temperature_zone: ì˜¨ë„ëŒ€ (ëƒ‰ë™/ëƒ‰ì¥/ìƒì˜¨) **í•„ìˆ˜**
- pickup_address: ìƒì°¨ì§€ ì£¼ì†Œ **í•„ìˆ˜**
- delivery_address: í•˜ì°¨ì§€ ì£¼ì†Œ **í•„ìˆ˜**
- pallet_count: íŒ”ë ˆíŠ¸ ìˆ˜ (ì •ìˆ˜) **í•„ìˆ˜**
- pickup_start_time: ìƒì°¨ ì‹œì‘ ì‹œê°„ (HH:MM)
- delivery_start_time: í•˜ì°¨ ì‹œì‘ ì‹œê°„ (HH:MM)
- notes: ë¹„ê³ 

**ì˜ë„ ë¶„ë¥˜:**
- create_order: ë‹¨ì¼ ì£¼ë¬¸ ë“±ë¡
- create_multiple_orders: ì—¬ëŸ¬ ì£¼ë¬¸ ì¼ê´„ ë“±ë¡ (1:N ë°°ì†¡)
- update_order: ê¸°ì¡´ ì£¼ë¬¸ ìˆ˜ì •
- query_order: ì£¼ë¬¸ ì¡°íšŒ
- need_more_info: ì •ë³´ ë¶€ì¡±
- unknown: ì´í•´í•  ìˆ˜ ì—†ëŠ” ìš”ì²­

**1:N ë°°ì†¡ íŒ¨í„´ ì¸ì‹:**
ì‚¬ìš©ìê°€ "ìƒì°¨ì§€ 1ê³³ â†’ í•˜ì°¨ì§€ ì—¬ëŸ¬ ê³³" íŒ¨í„´ìœ¼ë¡œ ì…ë ¥í•˜ë©´ ì—¬ëŸ¬ ì£¼ë¬¸ìœ¼ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.

ì˜ˆì‹œ ì…ë ¥:
- "ì„œìš¸ì—ì„œ ë¶€ì‚° 10p, ëŒ€êµ¬ 15p, ê´‘ì£¼ 8p ëƒ‰ë™"
- "ë¶€ì‚° 10íŒ”ë ˆíŠ¸, ëŒ€êµ¬ 15íŒ”ë ˆíŠ¸"
- "ì„œìš¸ ì°½ê³ ì—ì„œ 12ê³³ ë°°ì†¡: ë¶€ì‚° 10p, ëŒ€êµ¬ 15p..."

**ì‘ë‹µ í˜•ì‹ (JSON):**

ë‹¨ì¼ ì£¼ë¬¸:
{
    "intent": "create_order",
    "message": "ë‹¤ìŒ ì •ë³´ë¡œ ì£¼ë¬¸ì„ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\\n\\nâ€¢ ì˜¨ë„ëŒ€: ëƒ‰ë™\\nâ€¢ ìƒì°¨ì§€: ì„œìš¸\\n...",
    "parsed_order": { /* ì£¼ë¬¸ ì •ë³´ */ }
}

ì—¬ëŸ¬ ì£¼ë¬¸ (1:N):
{
    "intent": "create_multiple_orders",
    "message": "ë‹¤ìŒ Nê°œ ì£¼ë¬¸ì„ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\\n\\n...",
    "parsed_orders": [
        { "pickup_address": "ì„œìš¸", "delivery_address": "ë¶€ì‚°", "pallet_count": 10, "temperature_zone": "ëƒ‰ë™" },
        { "pickup_address": "ì„œìš¸", "delivery_address": "ëŒ€êµ¬", "pallet_count": 15, "temperature_zone": "ëƒ‰ë™" }
    ]
}

ì •ë³´ ë¶€ì¡±:
{
    "intent": "need_more_info",
    "message": "ì£¼ë¬¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:\\nâ€¢ ì˜¨ë„ëŒ€ (ëƒ‰ë™/ëƒ‰ì¥/ìƒì˜¨)\\nâ€¢ ìƒì°¨ì§€ ë˜ëŠ” í•˜ì°¨ì§€\\nâ€¢ íŒ”ë ˆíŠ¸ ìˆ˜",
    "parsed_order": { /* ì§€ê¸ˆê¹Œì§€ ì¶”ì¶œëœ ì •ë³´ */ }
}

**ê·œì¹™:**
1. í•„ìˆ˜ ì •ë³´: ì˜¨ë„ëŒ€, ìƒì°¨ì§€ OR í•˜ì°¨ì§€, íŒ”ë ˆíŠ¸ ìˆ˜
2. ì‹œê°„ í‘œí˜„: HH:MM í˜•ì‹ (ì˜ˆ: "ì˜¤ì „ 9ì‹œ" â†’ "09:00")
3. ë‚ ì§œ í‘œí˜„: YYYY-MM-DD (ì˜ˆ: "ë‚´ì¼" â†’ ì˜¤ëŠ˜ ê¸°ì¤€ ë‚´ì¼ ë‚ ì§œ)
4. "p", "P", "pallet" â†’ pallet_countë¡œ í•´ì„
5. í•˜ì°¨ì§€ê°€ ì—¬ëŸ¬ ê°œë©´ parsed_orders ë°°ì—´ë¡œ ë°˜í™˜
6. ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSONì´ì–´ì•¼ í•©ë‹ˆë‹¤."""
    
    def _build_user_prompt(self, message: str, context: Dict[str, Any]) -> str:
        """
        ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        today = date.today().isoformat()
        tomorrow = (date.today() + timedelta(days=1)).isoformat()
        
        prompt_parts = [
            f"**í˜„ì¬ ë‚ ì§œ:** {today}",
            f"**ë‚´ì¼ ë‚ ì§œ:** {tomorrow}",
            f"",
            f"**ì‚¬ìš©ì ì…ë ¥:**",
            f"{message}",
            f"",
            "ìœ„ ì…ë ¥ì—ì„œ ì£¼ë¬¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì ì ˆí•œ intentì™€ messageë¥¼ ìƒì„±í•˜ì„¸ìš”.",
            "í•˜ì°¨ì§€ê°€ ì—¬ëŸ¬ ê°œë©´ parsed_orders ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”."
        ]
        
        if context.get("pending_order") or context.get("pending_orders"):
            prompt_parts.append(f"\n**í˜„ì¬ í™•ì¸ ëŒ€ê¸° ì¤‘ì¸ ì£¼ë¬¸ì´ ìˆìŠµë‹ˆë‹¤.**")
        
        return "\n".join(prompt_parts)
        
        if context.get("recent_messages"):
            messages_str = "\n".join([f"- {m['role']}: {m['content']}" for m in context['recent_messages'][-3:]])
            prompt_parts.append(f"\nìµœê·¼ ëŒ€í™”:\n{messages_str}")
        
        return "\n".join(prompt_parts)
    
    def _calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> tuple:
        """
        ëª¨ë¸ë³„ í† í°ë‹¹ ë¹„ìš© ê³„ì‚° (USD)
        
        Args:
            model: ëª¨ë¸ëª… (gpt-4o, gpt-3.5-turbo, etc.)
            prompt_tokens: ì…ë ¥ í† í° ìˆ˜
            completion_tokens: ì¶œë ¥ í† í° ìˆ˜
        
        Returns:
            (prompt_cost, completion_cost) íŠœí”Œ
        """
        
        # ëª¨ë¸ë³„ ë¹„ìš© ì •ì˜ (per 1M tokens)
        # ì¶œì²˜: https://openai.com/pricing
        pricing = {
            "gpt-4o": {
                "prompt": 5.0,      # $5 / 1M input tokens
                "completion": 15.0   # $15 / 1M output tokens
            },
            "gpt-4-turbo": {
                "prompt": 10.0,     # $10 / 1M input tokens
                "completion": 30.0   # $30 / 1M output tokens
            },
            "gpt-3.5-turbo": {
                "prompt": 0.5,      # $0.5 / 1M input tokens
                "completion": 1.5    # $1.5 / 1M output tokens
            },
            "gemini-pro": {
                "prompt": 0.0,      # ë¬´ë£Œ (ì¼ì¼ ì œí•œ ìˆìŒ)
                "completion": 0.0
            }
        }
        
        # ëª¨ë¸ ê°€ê²© ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: gpt-4o)
        model_pricing = pricing.get(model, pricing["gpt-4o"])
        
        # ë¹„ìš© ê³„ì‚° (í† í° ìˆ˜ / 1,000,000 * ë‹¨ê°€)
        prompt_cost = (prompt_tokens / 1_000_000) * model_pricing["prompt"]
        completion_cost = (completion_tokens / 1_000_000) * model_pricing["completion"]
        
        return (prompt_cost, completion_cost)
