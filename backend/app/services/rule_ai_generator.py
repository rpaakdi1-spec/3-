"""
AI ê¸°ë°˜ ë°°ì°¨ ê·œì¹™ ìë™ ìƒì„± ì„œë¹„ìŠ¤

ê·œì¹™ ì´ë¦„ê³¼ ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬ conditionsì™€ actionsë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
"""
import logging
import json
import os
from typing import Dict, Any, Optional, Tuple

logger = logging.getLogger(__name__)

# OpenAI ë˜ëŠ” Gemini ì‚¬ìš©
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False


class RuleAIGenerator:
    """AI ê¸°ë°˜ ê·œì¹™ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.openai_client = None
        self.gemini_model = None
        
        # OpenAI ì„¤ì •
        openai_key = os.getenv("OPENAI_API_KEY")
        if OPENAI_AVAILABLE and openai_key:
            try:
                self.openai_client = OpenAI(api_key=openai_key)
                logger.info("âœ… OpenAI client initialized for rule generation")
            except Exception as e:
                logger.warning(f"âš ï¸ OpenAI initialization failed: {e}")
        
        # Gemini ì„¤ì •
        gemini_key = os.getenv("GEMINI_API_KEY")
        if GEMINI_AVAILABLE and gemini_key:
            try:
                genai.configure(api_key=gemini_key)
                self.gemini_model = genai.GenerativeModel('gemini-pro')
                logger.info("âœ… Gemini model initialized for rule generation")
            except Exception as e:
                logger.warning(f"âš ï¸ Gemini initialization failed: {e}")
    
    async def generate_rule(
        self,
        name: str,
        description: str,
        rule_type: str = "assignment"
    ) -> Dict[str, Any]:
        """
        ê·œì¹™ ì´ë¦„ê³¼ ì„¤ëª…ìœ¼ë¡œë¶€í„° conditionsì™€ actions ìë™ ìƒì„±
        
        Args:
            name: ê·œì¹™ ì´ë¦„ (ì˜ˆ: "ì§€ê²Œì°¨ê°€ëŠ¥ê±°ë˜ì²˜ -> ì§€ê²Œì°¨ê°€ëŠ¥ê¸°ì‚¬ë¡œ ë°°ì°¨")
            description: ê·œì¹™ ì„¤ëª…
            rule_type: assignment, constraint, optimization
            
        Returns:
            {
                "conditions": {...},
                "actions": {...},
                "confidence": 0.0-1.0,
                "reasoning": "ìƒì„± ì´ìœ "
            }
        """
        try:
            # AI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(name, description, rule_type)
            
            # AI ëª¨ë¸ í˜¸ì¶œ (OpenAI ìš°ì„ , Gemini ëŒ€ì²´)
            if self.openai_client:
                result = await self._generate_with_openai(prompt)
            elif self.gemini_model:
                result = await self._generate_with_gemini(prompt)
            else:
                # AI ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜ ìƒì„±
                result = self._generate_rule_based(name, description, rule_type)
            
            logger.info(f"âœ… Generated rule: {result}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Rule generation failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ë¹ˆ ê·œì¹™ ë°˜í™˜
            return {
                "conditions": {},
                "actions": {},
                "confidence": 0.0,
                "reasoning": f"ìƒì„± ì‹¤íŒ¨: {str(e)}"
            }
    
    def _build_prompt(self, name: str, description: str, rule_type: str) -> str:
        """AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = f"""ë‹¹ì‹ ì€ ë¬¼ë¥˜ ë°°ì°¨ ì‹œìŠ¤í…œì˜ ê·œì¹™ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ë°°ì°¨ ê·œì¹™ì„ ë§Œë“¤ê³  ì‹¶ì–´í•©ë‹ˆë‹¤:

**ê·œì¹™ ì´ë¦„**: {name}
**ê·œì¹™ ì„¤ëª…**: {description}
**ê·œì¹™ íƒ€ì…**: {rule_type}

ì´ ê·œì¹™ì„ JSON í˜•íƒœì˜ ì¡°ê±´(conditions)ê³¼ ì•¡ì…˜(actions)ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

## ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œ

### Conditions (ì¡°ê±´)
- order.temperature_zone: "ëƒ‰ë™", "ëƒ‰ì¥", "ìƒì˜¨"
- order.estimated_distance_km: ê±°ë¦¬ (ìˆ«ì)
- order.total_pallets: íŒ”ë ˆíŠ¸ ìˆ˜ (ìˆ«ì)
- order.weight_kg: ì¤‘ëŸ‰ (ìˆ«ì)
- order.pickup_client_id: ê³ ê° ID (ìˆ«ì)
- client.requires_forklift: ì§€ê²Œì°¨ í•„ìš” ì—¬ë¶€ (true/false)
- client.special_requirements: íŠ¹ìˆ˜ ìš”êµ¬ì‚¬í•­ (ë¬¸ìì—´)
- vehicle.vehicle_type: "ëƒ‰ë™íƒ‘ì°¨", "ëƒ‰ì¥íƒ‘ì°¨", "ìƒì˜¨íƒ‘ì°¨"

### Actions (ì•¡ì…˜)
- prefer_vehicle_type: ì„ í˜¸ ì°¨ëŸ‰ íƒ€ì…
- require_driver_skill: í•„ìš” ê¸°ì‚¬ ê¸°ìˆ  (ì˜ˆ: "forklift", "hazmat")
- priority_weight: ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ (1.0-2.0)
- max_distance_km: ìµœëŒ€ ê±°ë¦¬ ì œí•œ
- prefer_driver_id: ì„ í˜¸ ê¸°ì‚¬ ID
- require_vehicle_capacity: í•„ìš” ì°¨ëŸ‰ ìš©ëŸ‰

### ê±°ë¦¬ ì¡°ê±´ í‘œí˜„
- {{"$gte": 50}} - 50 ì´ìƒ
- {{"$lte": 100}} - 100 ì´í•˜
- {{"$between": [50, 100]}} - 50-100 ì‚¬ì´

## ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥)

{{
  "conditions": {{
    "ì¡°ê±´_í•„ë“œëª…": ì¡°ê±´_ê°’
  }},
  "actions": {{
    "ì•¡ì…˜_í•„ë“œëª…": ì•¡ì…˜_ê°’
  }},
  "confidence": 0.85,
  "reasoning": "ì´ ê·œì¹™ì„ ì´ë ‡ê²Œ í•´ì„í–ˆìŠµë‹ˆë‹¤: ..."
}}

**ì¤‘ìš”**: JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ë„£ì§€ ë§ˆì„¸ìš”.
"""
        return prompt
    
    async def _generate_with_openai(self, prompt: str) -> Dict[str, Any]:
        """OpenAIë¡œ ê·œì¹™ ìƒì„±"""
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a logistics dispatch rule expert. Always respond in valid JSON format only."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON ì¶”ì¶œ (```json ... ``` ì œê±°)
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            logger.error(f"OpenAI generation error: {e}")
            raise
    
    async def _generate_with_gemini(self, prompt: str) -> Dict[str, Any]:
        """Geminië¡œ ê·œì¹™ ìƒì„±"""
        try:
            response = self.gemini_model.generate_content(prompt)
            content = response.text.strip()
            
            # JSON ì¶”ì¶œ
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            logger.error(f"Gemini generation error: {e}")
            raise
    
    def _generate_rule_based(
        self,
        name: str,
        description: str,
        rule_type: str
    ) -> Dict[str, Any]:
        """
        AI ì—†ì´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ìƒì„± (í´ë°±)
        
        í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê°„ë‹¨í•œ ê·œì¹™ ìƒì„±
        ìš°ì„ ìˆœìœ„: ì§€ê²Œì°¨ > ì˜¨ë„ > ê±°ë¦¬ > ì¤‘ëŸ‰
        """
        conditions = {}
        actions = {}
        reasoning = []
        
        text = (name + " " + description).lower()
        
        # ìš°ì„ ìˆœìœ„ 1: ì§€ê²Œì°¨ ê´€ë ¨ (ê°€ì¥ ëª…í™•í•œ ìš”êµ¬ì‚¬í•­)
        if "ì§€ê²Œì°¨" in text or "forklift" in text:
            conditions["client.requires_forklift"] = True
            actions["require_driver_skill"] = "forklift"
            actions["priority_weight"] = 1.5
            reasoning.append("ì§€ê²Œì°¨ ìš”êµ¬ì‚¬í•­ ê°ì§€")
            
            # ì§€ê²Œì°¨ ê·œì¹™ì´ë©´ ì˜¨ë„ëŠ” ë¬´ì‹œ (ì§€ê²Œì°¨ê°€ ì£¼ ì¡°ê±´)
            logger.info(f"ğŸ”§ Forklift rule detected, ignoring temperature keywords")
        
        # ìš°ì„ ìˆœìœ„ 2: ì˜¨ë„ ê´€ë ¨ (ì§€ê²Œì°¨ ê·œì¹™ì´ ì•„ë‹ ë•Œë§Œ)
        elif "ëƒ‰ë™" in text:
            conditions["order.temperature_zone"] = "ëƒ‰ë™"
            actions["prefer_vehicle_type"] = "ëƒ‰ë™íƒ‘ì°¨"
            reasoning.append("ëƒ‰ë™ ì˜¨ë„ëŒ€ ê°ì§€")
        elif "ëƒ‰ì¥" in text:
            conditions["order.temperature_zone"] = "ëƒ‰ì¥"
            actions["prefer_vehicle_type"] = "ëƒ‰ì¥íƒ‘ì°¨"
            reasoning.append("ëƒ‰ì¥ ì˜¨ë„ëŒ€ ê°ì§€")
        elif "ìƒì˜¨" in text:
            conditions["order.temperature_zone"] = "ìƒì˜¨"
            actions["prefer_vehicle_type"] = "ìƒì˜¨íƒ‘ì°¨"
            reasoning.append("ìƒì˜¨ ê°ì§€")
        
        # ìš°ì„ ìˆœìœ„ 3: ê±°ë¦¬ ê´€ë ¨
        import re
        distance_match = re.search(r'(\d+)\s*km\s*(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ)', text)
        if distance_match:
            distance = int(distance_match.group(1))
            operator = distance_match.group(2)
            
            if operator in ["ì´ìƒ", "ì´ˆê³¼"]:
                conditions["order.estimated_distance_km"] = {"$gte": distance}
                reasoning.append(f"{distance}km ì´ìƒ ì¡°ê±´ ê°ì§€")
                # ê±°ë¦¬ ì œí•œì´ ìˆìœ¼ë©´ ì°¨ëŸ‰ ìš©ëŸ‰ë„ ì¶”ê°€
                if distance >= 100:
                    actions["prefer_vehicle_weight"] = 5000
                    reasoning.append("ì¥ê±°ë¦¬ëŠ” ëŒ€í˜• ì°¨ëŸ‰ ì„ í˜¸")
            elif operator in ["ì´í•˜", "ë¯¸ë§Œ"]:
                conditions["order.estimated_distance_km"] = {"$lte": distance}
                reasoning.append(f"{distance}km ì´í•˜ ì¡°ê±´ ê°ì§€")
        
        # ìš°ì„ ìˆœìœ„ 4: ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
        if "ìš°ì„ " in text or "ë¨¼ì €" in text:
            if "priority_weight" not in actions:
                actions["priority_weight"] = 1.3
            reasoning.append("ìš°ì„ ìˆœìœ„ ì„¤ì •")
        
        # ê²½ê³ : ì¡°ê±´ì´ ì—†ìœ¼ë©´ ë‚®ì€ ì‹ ë¢°ë„
        if not conditions:
            logger.warning(f"âš ï¸ No conditions detected from: '{name}' - '{description}'")
            confidence = 0.2
            reasoning.append("âš ï¸ ëª…í™•í•œ ì¡°ê±´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì¡°ê±´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not actions:
            logger.warning(f"âš ï¸ No actions detected from: '{name}' - '{description}'")
            confidence = 0.3
            reasoning.append("âš ï¸ ëª…í™•í•œ ì•¡ì…˜ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì•¡ì…˜ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            # ì¡°ê±´ê³¼ ì•¡ì…˜ì´ ëª¨ë‘ ìˆìœ¼ë©´ ì¤‘ê°„ ì‹ ë¢°ë„
            confidence = 0.65
        
        result = {
            "conditions": conditions,
            "actions": actions,
            "confidence": confidence,
            "reasoning": "ê·œì¹™ ê¸°ë°˜ ìƒì„±: " + ", ".join(reasoning) if reasoning else "íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. AI ëª¨ë¸(OpenAI/Gemini)ì„ ì„¤ì •í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤."
        }
        
        logger.info(f"ğŸ“‹ Rule-based generation result: confidence={confidence:.2f}, conditions={len(conditions)}, actions={len(actions)}")
        return result
