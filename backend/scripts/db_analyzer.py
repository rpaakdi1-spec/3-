"""
ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ë° ìµœì í™” ë„êµ¬
ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„, ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  ë¶„ì„, ëŠë¦° ì¿¼ë¦¬ ì‹ë³„
"""
import sys
import os
from typing import List, Dict, Any
from sqlalchemy import create_engine, text, inspect
from sqlalchemy.orm import sessionmaker
from datetime import datetime
from loguru import logger

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.core.config import settings


class DatabaseAnalyzer:
    """ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, database_url: str = None):
        self.database_url = database_url or settings.DATABASE_URL
        self.engine = create_engine(self.database_url)
        self.Session = sessionmaker(bind=self.engine)
        self.inspector = inspect(self.engine)
    
    def analyze_table_sizes(self) -> List[Dict[str, Any]]:
        """í…Œì´ë¸” í¬ê¸° ë¶„ì„"""
        logger.info("ğŸ“Š í…Œì´ë¸” í¬ê¸° ë¶„ì„ ì¤‘...")
        
        results = []
        tables = self.inspector.get_table_names()
        
        with self.Session() as session:
            for table in tables:
                try:
                    # PostgreSQL
                    if 'postgresql' in self.database_url:
                        query = text(f"""
                            SELECT 
                                '{table}' as table_name,
                                pg_size_pretty(pg_total_relation_size('{table}')) as total_size,
                                pg_size_pretty(pg_relation_size('{table}')) as table_size,
                                pg_size_pretty(pg_indexes_size('{table}')) as indexes_size,
                                (SELECT COUNT(*) FROM {table}) as row_count
                        """)
                        result = session.execute(query).fetchone()
                        results.append({
                            'table_name': result[0],
                            'total_size': result[1],
                            'table_size': result[2],
                            'indexes_size': result[3],
                            'row_count': result[4]
                        })
                    # SQLite
                    else:
                        query = text(f"SELECT COUNT(*) FROM {table}")
                        count = session.execute(query).scalar()
                        results.append({
                            'table_name': table,
                            'row_count': count
                        })
                except Exception as e:
                    logger.warning(f"í…Œì´ë¸” {table} ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return results
    
    def analyze_indexes(self) -> Dict[str, List[Dict]]:
        """ì¸ë±ìŠ¤ ë¶„ì„"""
        logger.info("ğŸ” ì¸ë±ìŠ¤ ë¶„ì„ ì¤‘...")
        
        results = {}
        tables = self.inspector.get_table_names()
        
        for table in tables:
            indexes = self.inspector.get_indexes(table)
            results[table] = indexes
        
        return results
    
    def check_missing_indexes(self) -> List[Dict[str, Any]]:
        """ëˆ„ë½ëœ ì¸ë±ìŠ¤ í™•ì¸"""
        logger.info("âš ï¸  ëˆ„ë½ëœ ì¸ë±ìŠ¤ í™•ì¸ ì¤‘...")
        
        recommendations = []
        
        # ì£¼ìš” ì™¸ë˜ í‚¤ ì»¬ëŸ¼ í™•ì¸
        fk_checks = {
            'orders': ['pickup_client_id', 'delivery_client_id'],
            'dispatches': ['vehicle_id', 'driver_id'],
            'dispatch_routes': ['dispatch_id', 'order_id'],
            'vehicle_locations': ['vehicle_id', 'dispatch_id']
        }
        
        existing_indexes = self.analyze_indexes()
        
        for table, columns in fk_checks.items():
            if table not in existing_indexes:
                continue
            
            table_indexes = existing_indexes[table]
            indexed_columns = set()
            for index in table_indexes:
                indexed_columns.update(index['column_names'])
            
            for column in columns:
                if column not in indexed_columns:
                    recommendations.append({
                        'table': table,
                        'column': column,
                        'reason': 'ì™¸ë˜ í‚¤ ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ì—†ìŒ',
                        'suggestion': f'CREATE INDEX idx_{table}_{column} ON {table}({column});'
                    })
        
        return recommendations
    
    def analyze_query_performance(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ (EXPLAIN)"""
        logger.info(f"ğŸ”¬ ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„: {query[:50]}...")
        
        with self.Session() as session:
            try:
                # PostgreSQL EXPLAIN ANALYZE
                if 'postgresql' in self.database_url:
                    explain_query = text(f"EXPLAIN ANALYZE {query}")
                    result = session.execute(explain_query)
                    explain_output = [row[0] for row in result]
                    return {
                        'query': query,
                        'explain': explain_output,
                        'database': 'postgresql'
                    }
                # SQLite EXPLAIN QUERY PLAN
                else:
                    explain_query = text(f"EXPLAIN QUERY PLAN {query}")
                    result = session.execute(explain_query)
                    explain_output = [dict(row) for row in result]
                    return {
                        'query': query,
                        'explain': explain_output,
                        'database': 'sqlite'
                    }
            except Exception as e:
                logger.error(f"ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
                return {'error': str(e)}
    
    def get_connection_pool_stats(self) -> Dict[str, Any]:
        """ì»¤ë„¥ì…˜ í’€ í†µê³„"""
        pool = self.engine.pool
        return {
            'pool_size': pool.size(),
            'checked_in': pool.checkedin(),
            'checked_out': pool.checkedout(),
            'overflow': pool.overflow(),
            'status': 'healthy' if pool.checkedin() > 0 else 'warning'
        }
    
    def optimize_vacuum(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ (PostgreSQL VACUUM, SQLite VACUUM)"""
        logger.info("ğŸ§¹ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì¤‘...")
        
        with self.Session() as session:
            try:
                if 'postgresql' in self.database_url:
                    # PostgreSQL VACUUM ANALYZE
                    session.execute(text("VACUUM ANALYZE"))
                    logger.success("âœ… PostgreSQL VACUUM ANALYZE ì™„ë£Œ")
                else:
                    # SQLite VACUUM
                    session.execute(text("VACUUM"))
                    logger.success("âœ… SQLite VACUUM ì™„ë£Œ")
                session.commit()
            except Exception as e:
                logger.error(f"VACUUM ì‹¤íŒ¨: {e}")
    
    def generate_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("ğŸ“ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report = []
        report.append("=" * 80)
        report.append(f"ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ë³´ê³ ì„œ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 80)
        report.append("")
        
        # 1. í…Œì´ë¸” í¬ê¸°
        report.append("ğŸ“Š í…Œì´ë¸” í¬ê¸° ë¶„ì„")
        report.append("-" * 80)
        table_sizes = self.analyze_table_sizes()
        for table in table_sizes:
            if 'total_size' in table:
                report.append(f"  {table['table_name']:30} | "
                            f"Total: {table['total_size']:15} | "
                            f"Table: {table['table_size']:15} | "
                            f"Indexes: {table['indexes_size']:15} | "
                            f"Rows: {table['row_count']:>10,}")
            else:
                report.append(f"  {table['table_name']:30} | Rows: {table['row_count']:>10,}")
        report.append("")
        
        # 2. ì¸ë±ìŠ¤ í˜„í™©
        report.append("ğŸ” ì¸ë±ìŠ¤ í˜„í™©")
        report.append("-" * 80)
        indexes = self.analyze_indexes()
        for table, table_indexes in indexes.items():
            report.append(f"  í…Œì´ë¸”: {table}")
            if table_indexes:
                for idx in table_indexes:
                    columns = ', '.join(idx['column_names'])
                    unique = ' (UNIQUE)' if idx.get('unique') else ''
                    report.append(f"    - {idx['name']}: {columns}{unique}")
            else:
                report.append(f"    ì¸ë±ìŠ¤ ì—†ìŒ")
        report.append("")
        
        # 3. ëˆ„ë½ëœ ì¸ë±ìŠ¤
        report.append("âš ï¸  ì¸ë±ìŠ¤ ê¶Œì¥ì‚¬í•­")
        report.append("-" * 80)
        missing = self.check_missing_indexes()
        if missing:
            for rec in missing:
                report.append(f"  [{rec['table']}.{rec['column']}]")
                report.append(f"    ì´ìœ : {rec['reason']}")
                report.append(f"    ê¶Œì¥: {rec['suggestion']}")
        else:
            report.append("  ëª¨ë“  í•„ìˆ˜ ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        report.append("")
        
        # 4. ì»¤ë„¥ì…˜ í’€ ìƒíƒœ
        report.append("ğŸ”Œ ì»¤ë„¥ì…˜ í’€ ìƒíƒœ")
        report.append("-" * 80)
        pool_stats = self.get_connection_pool_stats()
        report.append(f"  Pool Size: {pool_stats['pool_size']}")
        report.append(f"  Checked In: {pool_stats['checked_in']}")
        report.append(f"  Checked Out: {pool_stats['checked_out']}")
        report.append(f"  Overflow: {pool_stats['overflow']}")
        report.append(f"  Status: {pool_stats['status']}")
        report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.add("logs/db_analysis.log", rotation="1 day")
    
    analyzer = DatabaseAnalyzer()
    
    # ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_report()
    print(report)
    
    # íŒŒì¼ë¡œ ì €ì¥
    report_file = f"db_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    logger.success(f"âœ… ë³´ê³ ì„œê°€ {report_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # VACUUM ì‹¤í–‰ (ì„ íƒì‚¬í•­)
    if input("\nVACUUMì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
        analyzer.optimize_vacuum()


if __name__ == "__main__":
    main()
