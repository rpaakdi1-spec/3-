# Phase 4 Week 11-12: í†µí•© & ë°°í¬ ë¡œë“œë§µ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**ê¸°ê°„**: 2026-02-05 ~ 2026-03-19 (2ì£¼)  
**ëª©í‘œ**: ì „ì²´ ì‹œìŠ¤í…œ í†µí•©, í…ŒìŠ¤íŠ¸, ìµœì í™” ë° í”„ë¡œë•ì…˜ ë°°í¬  
**ì˜ˆìƒ ê°€ì¹˜**: â‚©36,000,000/ë…„  
**ìƒíƒœ**: ğŸŸ¡ ì§„í–‰ ì¤‘

---

## ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ

### í•µì‹¬ KPI
- ğŸš€ **ì‹œìŠ¤í…œ ê°€ìš©ì„±**: 99.9% (ì—°ê°„ ë‹¤ìš´íƒ€ì„ < 8.76ì‹œê°„)
- âš¡ **í‰ê·  ì‘ë‹µ ì‹œê°„**: < 200ms
- ğŸ“Š **ë™ì‹œ ì ‘ì†ì**: 1,000ëª… ì´ìƒ ì²˜ë¦¬
- ğŸ”’ **ë³´ì•ˆ ì·¨ì•½ì **: 0ê°œ
- ğŸ“ˆ **ë°°í¬ ì„±ê³µë¥ **: 100%
- ğŸ”„ **ìë™í™”ìœ¨**: 95%

### ROI ê³„ì‚°
```
ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ: â‚©18M
  - ë‹¤ìš´íƒ€ì„ ê°ì†Œ: â‚©10M
  - ì¥ì•  ëŒ€ì‘ ì‹œê°„ ë‹¨ì¶•: â‚©8M

ì„±ëŠ¥ ìµœì í™”: â‚©12M
  - ì„œë²„ ë¹„ìš© ì ˆê°: â‚©7M
  - ì‘ë‹µ ì‹œê°„ ê°œì„ : â‚©5M

ìš´ì˜ ìë™í™”: â‚©6M
  - ë°°í¬ ì‹œê°„ ë‹¨ì¶•: â‚©4M
  - ìˆ˜ë™ ì‘ì—… ê°ì†Œ: â‚©2M

ì´ ì—°ê°„ ì ˆê°: â‚©36,000,000
íˆ¬ì ë¹„ìš©: â‚©3,000,000
ROI: 1,100%
íˆ¬ì íšŒìˆ˜ ê¸°ê°„: 1ê°œì›”
```

---

## ğŸ—ï¸ ì£¼ìš” ì‘ì—…

### 1. Docker ì»¨í…Œì´ë„ˆí™” â­

#### ë°±ì—”ë“œ Docker ì„¤ì •
**íŒŒì¼**: `backend/Dockerfile`
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/api/v1/health || exit 1

# ì‹¤í–‰
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

#### í”„ë¡ íŠ¸ì—”ë“œ Docker ì„¤ì •
**íŒŒì¼**: `frontend/Dockerfile`
```dockerfile
# Build stage
FROM node:18-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine

COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

#### Docker Compose
**íŒŒì¼**: `docker-compose.yml`
```yaml
version: '3.8'

services:
  # PostgreSQL
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: uvis_db
      POSTGRES_USER: uvis_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uvis_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://uvis_user:${DB_PASSWORD}@db:5432/uvis_db
      REDIS_URL: redis://redis:6379
      JWT_SECRET: ${JWT_SECRET}
      APP_ENV: production
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - ./uploads:/app/uploads
    restart: unless-stopped

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: unless-stopped

  # Nginx (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

---

### 2. CI/CD íŒŒì´í”„ë¼ì¸ â­

#### GitHub Actions
**íŒŒì¼**: `.github/workflows/deploy.yml`
```yaml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
      
      - name: Run tests
        run: |
          cd backend
          pytest tests/ -v --cov=app --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./backend/coverage.xml

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build and push backend
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: uvis/backend:latest
      
      - name: Build and push frontend
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          push: true
          tags: uvis/frontend:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    
    steps:
      - name: Deploy to production
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PROD_HOST }}
          username: ${{ secrets.PROD_USER }}
          key: ${{ secrets.PROD_SSH_KEY }}
          script: |
            cd /opt/uvis
            docker-compose pull
            docker-compose up -d
            docker-compose exec -T backend alembic upgrade head
```

---

### 3. ëª¨ë‹ˆí„°ë§ & ë¡œê¹… â­

#### Prometheus ì„¤ì •
**íŒŒì¼**: `monitoring/prometheus.yml`
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'fastapi'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
```

#### Grafana ëŒ€ì‹œë³´ë“œ
**íŒŒì¼**: `monitoring/grafana/dashboards/system.json`
```json
{
  "dashboard": {
    "title": "UVIS System Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Response Time",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
          }
        ]
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])"
          }
        ]
      }
    ]
  }
}
```

#### ELK Stack (ë¡œê·¸ ìˆ˜ì§‘)
**íŒŒì¼**: `monitoring/logstash/logstash.conf`
```conf
input {
  file {
    path => "/var/log/uvis/*.log"
    start_position => "beginning"
    codec => json
  }
}

filter {
  if [level] == "ERROR" {
    mutate {
      add_tag => ["error"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "uvis-logs-%{+YYYY.MM.dd}"
  }
}
```

---

### 4. ë³´ì•ˆ ê°•í™” â­

#### ë³´ì•ˆ í—¤ë” ì„¤ì •
**íŒŒì¼**: `backend/app/middleware/security.py`
```python
from fastapi import Request
from fastapi.responses import Response
from starlette.middleware.base import BaseHTTPMiddleware

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # Security headers
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        response.headers["Content-Security-Policy"] = "default-src 'self'"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        
        return response
```

#### Rate Limiting
**íŒŒì¼**: `backend/app/middleware/rate_limit.py`
```python
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
from redis import Redis
import time

class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, redis_url: str, requests_per_minute: int = 60):
        super().__init__(app)
        self.redis = Redis.from_url(redis_url)
        self.requests_per_minute = requests_per_minute
    
    async def dispatch(self, request: Request, call_next):
        client_ip = request.client.host
        key = f"rate_limit:{client_ip}"
        
        current = self.redis.get(key)
        
        if current and int(current) >= self.requests_per_minute:
            raise HTTPException(status_code=429, detail="Too many requests")
        
        pipe = self.redis.pipeline()
        pipe.incr(key)
        pipe.expire(key, 60)
        pipe.execute()
        
        response = await call_next(request)
        return response
```

#### SQL Injection ë°©ì§€
- âœ… SQLAlchemy ORM ì‚¬ìš© (Parameterized queries)
- âœ… ì…ë ¥ ê²€ì¦ (Pydantic)
- âœ… Prepared statements

#### XSS ë°©ì§€
- âœ… Content Security Policy
- âœ… HTML ì´ìŠ¤ì¼€ì´í•‘
- âœ… ì…ë ¥ sanitization

---

### 5. ì„±ëŠ¥ ìµœì í™” â­

#### ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
**íŒŒì¼**: `backend/alembic/versions/add_indexes.py`
```python
"""Add performance indexes

Revision ID: xxx
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # ìì£¼ ì¡°íšŒë˜ëŠ” ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ì¶”ê°€
    op.create_index('idx_orders_status', 'orders', ['status'])
    op.create_index('idx_orders_created_at', 'orders', ['created_at'])
    op.create_index('idx_dispatches_status', 'dispatches', ['status'])
    op.create_index('idx_dispatches_driver_id', 'dispatches', ['driver_id'])
    op.create_index('idx_vehicles_license_plate', 'vehicles', ['license_plate'])
    
    # ë³µí•© ì¸ë±ìŠ¤
    op.create_index(
        'idx_orders_status_created',
        'orders',
        ['status', 'created_at']
    )
    
    # Full-text search ì¸ë±ìŠ¤
    op.execute("""
        CREATE INDEX idx_orders_address_fts 
        ON orders 
        USING gin(to_tsvector('korean', pickup_address || ' ' || delivery_address))
    """)

def downgrade():
    op.drop_index('idx_orders_status')
    op.drop_index('idx_orders_created_at')
    op.drop_index('idx_dispatches_status')
    op.drop_index('idx_dispatches_driver_id')
    op.drop_index('idx_vehicles_license_plate')
    op.drop_index('idx_orders_status_created')
    op.drop_index('idx_orders_address_fts')
```

#### Redis ìºì‹± ì „ëµ
**íŒŒì¼**: `backend/app/core/cache.py`
```python
from redis import Redis
from functools import wraps
import json
import hashlib

class CacheManager:
    def __init__(self, redis_url: str):
        self.redis = Redis.from_url(redis_url)
    
    def cache(self, ttl: int = 300):
        """ìºì‹± ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # ìºì‹œ í‚¤ ìƒì„±
                cache_key = self._generate_key(func.__name__, args, kwargs)
                
                # ìºì‹œ í™•ì¸
                cached = self.redis.get(cache_key)
                if cached:
                    return json.loads(cached)
                
                # í•¨ìˆ˜ ì‹¤í–‰
                result = await func(*args, **kwargs)
                
                # ìºì‹œ ì €ì¥
                self.redis.setex(
                    cache_key,
                    ttl,
                    json.dumps(result, default=str)
                )
                
                return result
            return wrapper
        return decorator
    
    def _generate_key(self, func_name: str, args, kwargs) -> str:
        key_data = f"{func_name}:{args}:{kwargs}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def invalidate(self, pattern: str):
        """ìºì‹œ ë¬´íš¨í™”"""
        for key in self.redis.scan_iter(pattern):
            self.redis.delete(key)
```

#### ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ í’€
**íŒŒì¼**: `backend/app/core/database.py`
```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,          # ê¸°ë³¸ ì»¤ë„¥ì…˜ ìˆ˜
    max_overflow=40,       # ì¶”ê°€ ì»¤ë„¥ì…˜ ìˆ˜
    pool_timeout=30,       # íƒ€ì„ì•„ì›ƒ
    pool_recycle=3600,     # ì»¤ë„¥ì…˜ ì¬ì‚¬ìš© ì£¼ê¸°
    pool_pre_ping=True,    # ì»¤ë„¥ì…˜ ìœ íš¨ì„± ì²´í¬
)
```

---

### 6. ë°±ì—… & ë³µêµ¬ â­

#### ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
**íŒŒì¼**: `scripts/backup.sh`
```bash
#!/bin/bash

# ì„¤ì •
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="uvis_db"
DB_USER="uvis_user"
RETENTION_DAYS=30

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "Starting database backup..."
pg_dump -U $DB_USER $DB_NAME | gzip > "$BACKUP_DIR/db_backup_$DATE.sql.gz"

# íŒŒì¼ ë°±ì—… (uploads)
echo "Starting file backup..."
tar -czf "$BACKUP_DIR/files_backup_$DATE.tar.gz" /app/uploads

# ì„¤ì • íŒŒì¼ ë°±ì—…
echo "Starting config backup..."
tar -czf "$BACKUP_DIR/config_backup_$DATE.tar.gz" /app/.env /app/docker-compose.yml

# S3ì— ì—…ë¡œë“œ
aws s3 cp "$BACKUP_DIR/db_backup_$DATE.sql.gz" s3://uvis-backups/
aws s3 cp "$BACKUP_DIR/files_backup_$DATE.tar.gz" s3://uvis-backups/
aws s3 cp "$BACKUP_DIR/config_backup_$DATE.tar.gz" s3://uvis-backups/

# ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find $BACKUP_DIR -name "*.gz" -mtime +$RETENTION_DAYS -delete

echo "Backup completed: $DATE"
```

#### ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
**íŒŒì¼**: `scripts/restore.sh`
```bash
#!/bin/bash

# ì‚¬ìš©ë²•: ./restore.sh backup_date
BACKUP_DATE=$1
BACKUP_DIR="/backups"

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
echo "Restoring database..."
gunzip < "$BACKUP_DIR/db_backup_$BACKUP_DATE.sql.gz" | psql -U uvis_user uvis_db

# íŒŒì¼ ë³µêµ¬
echo "Restoring files..."
tar -xzf "$BACKUP_DIR/files_backup_$BACKUP_DATE.tar.gz" -C /

echo "Restore completed"
```

#### Cron ì„¤ì •
```cron
# ë§¤ì¼ ìƒˆë²½ 3ì‹œ ë°±ì—…
0 3 * * * /opt/uvis/scripts/backup.sh >> /var/log/backup.log 2>&1

# ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 4ì‹œ ì „ì²´ ë°±ì—…
0 4 * * 0 /opt/uvis/scripts/full_backup.sh >> /var/log/backup.log 2>&1
```

---

### 7. í†µí•© í…ŒìŠ¤íŠ¸ â­

#### E2E í…ŒìŠ¤íŠ¸ (Pytest)
**íŒŒì¼**: `backend/tests/test_e2e.py`
```python
import pytest
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_order_to_dispatch_flow():
    """ì£¼ë¬¸ ìƒì„± â†’ ë°°ì°¨ â†’ ì™„ë£Œ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    # 1. ë¡œê·¸ì¸
    login_response = client.post("/api/v1/auth/login", data={
        "username": "test@example.com",
        "password": "testpass"
    })
    assert login_response.status_code == 200
    token = login_response.json()["access_token"]
    headers = {"Authorization": f"Bearer {token}"}
    
    # 2. ì£¼ë¬¸ ìƒì„±
    order_data = {
        "client_id": 1,
        "pickup_address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬",
        "delivery_address": "ë¶€ì‚°ì‹œ í•´ìš´ëŒ€êµ¬",
        "cargo_type": "ëƒ‰ì¥",
        "weight": 100.0
    }
    order_response = client.post(
        "/api/v1/orders",
        json=order_data,
        headers=headers
    )
    assert order_response.status_code == 201
    order_id = order_response.json()["id"]
    
    # 3. ë°°ì°¨ ìƒì„±
    dispatch_data = {
        "order_id": order_id,
        "vehicle_id": 1,
        "driver_id": 1
    }
    dispatch_response = client.post(
        "/api/v1/dispatches",
        json=dispatch_data,
        headers=headers
    )
    assert dispatch_response.status_code == 201
    dispatch_id = dispatch_response.json()["id"]
    
    # 4. ë°°ì°¨ ìƒíƒœ ì—…ë°ì´íŠ¸
    status_response = client.put(
        f"/api/v1/mobile/dispatches/{dispatch_id}/status",
        json={"status": "COMPLETED"},
        headers=headers
    )
    assert status_response.status_code == 200
    
    # 5. ì£¼ë¬¸ ìƒíƒœ í™•ì¸
    order_check = client.get(
        f"/api/v1/orders/{order_id}",
        headers=headers
    )
    assert order_check.json()["status"] == "COMPLETED"
```

#### ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Locust)
**íŒŒì¼**: `tests/load/locustfile.py`
```python
from locust import HttpUser, task, between

class UVISUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        """ë¡œê·¸ì¸"""
        response = self.client.post("/api/v1/auth/login", data={
            "username": "test@example.com",
            "password": "testpass"
        })
        self.token = response.json()["access_token"]
        self.headers = {"Authorization": f"Bearer {self.token}"}
    
    @task(3)
    def view_dispatches(self):
        """ë°°ì°¨ ëª©ë¡ ì¡°íšŒ"""
        self.client.get(
            "/api/v1/mobile/dispatches",
            headers=self.headers
        )
    
    @task(2)
    def view_dashboard(self):
        """ëŒ€ì‹œë³´ë“œ ì¡°íšŒ"""
        self.client.get(
            "/api/v1/mobile/summary",
            headers=self.headers
        )
    
    @task(1)
    def update_location(self):
        """ìœ„ì¹˜ ì—…ë°ì´íŠ¸"""
        self.client.post(
            "/api/v1/mobile/location",
            json={"latitude": 37.5665, "longitude": 126.9780},
            headers=self.headers
        )
```

---

## ğŸ“Š ê°œë°œ ì¼ì •

### Week 11 (2026-02-05 ~ 2026-02-11)

#### Day 1-2: Docker & CI/CD
- [x] Dockerfile ì‘ì„± (ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ)
- [x] docker-compose.yml ì‘ì„±
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ì •
- [ ] Docker Hub ì´ë¯¸ì§€ ë¹Œë“œ

#### Day 3-4: ëª¨ë‹ˆí„°ë§ & ë¡œê¹…
- [ ] Prometheus ì„¤ì •
- [ ] Grafana ëŒ€ì‹œë³´ë“œ
- [ ] ELK Stack êµ¬ì„±
- [ ] ì•Œë¦¼ ê·œì¹™ ì„¤ì •

#### Day 5-7: ë³´ì•ˆ & ìµœì í™”
- [ ] ë³´ì•ˆ í—¤ë” ë¯¸ë“¤ì›¨ì–´
- [ ] Rate limiting
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
- [ ] Redis ìºì‹±
- [ ] ì»¤ë„¥ì…˜ í’€ ìµœì í™”

### Week 12 (2026-02-12 ~ 2026-02-19)

#### Day 8-9: ë°±ì—… & ë³µêµ¬
- [ ] ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
- [ ] S3 í†µí•©
- [ ] ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
- [ ] Cron ì„¤ì •

#### Day 10-11: í†µí•© í…ŒìŠ¤íŠ¸
- [ ] E2E í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Locust)
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] ë³´ì•ˆ ìŠ¤ìº”

#### Day 12-13: ë¬¸ì„œí™”
- [ ] API ë¬¸ì„œ ì™„ì„±
- [ ] ë°°í¬ ê°€ì´ë“œ
- [ ] ìš´ì˜ ë§¤ë‰´ì–¼
- [ ] íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

#### Day 14: ìµœì¢… ë°°í¬
- [ ] í”„ë¡œë•ì…˜ ë°°í¬
- [ ] ëª¨ë‹ˆí„°ë§ í™•ì¸
- [ ] ì„±ëŠ¥ ê²€ì¦
- [ ] ì™„ë£Œ ë³´ê³ ì„œ

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### ì‹œìŠ¤í…œ ì„±ëŠ¥
- âœ… í‰ê·  ì‘ë‹µ ì‹œê°„ < 200ms
- âœ… ë™ì‹œ ì ‘ì†ì 1,000ëª… ì²˜ë¦¬
- âœ… 99.9% ê°€ìš©ì„±
- âœ… ì—ëŸ¬ìœ¨ < 0.1%

### ë³´ì•ˆ
- âœ… OWASP Top 10 ì·¨ì•½ì  0ê°œ
- âœ… SSL/TLS ì¸ì¦ì„œ ì ìš©
- âœ… API Rate limiting êµ¬í˜„
- âœ… ë³´ì•ˆ í—¤ë” ëª¨ë‘ ì ìš©

### ë°°í¬
- âœ… CI/CD íŒŒì´í”„ë¼ì¸ ìë™í™”
- âœ… ë¬´ì¤‘ë‹¨ ë°°í¬ (Blue-Green)
- âœ… ë¡¤ë°± ê°€ëŠ¥
- âœ… ë°°í¬ ì‹œê°„ < 5ë¶„

### ëª¨ë‹ˆí„°ë§
- âœ… ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
- âœ… ìë™ ì•Œë¦¼ (Slack/Email)
- âœ… ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„
- âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

---

## ğŸ“š ë¬¸ì„œ ì‘ì„± í•­ëª©

### 1. API ë¬¸ì„œ
- Swagger/OpenAPI ì™„ì„±
- ì¸ì¦ ë°©ë²•
- ì—”ë“œí¬ì¸íŠ¸ ì„¤ëª…
- ì˜ˆì œ ì½”ë“œ

### 2. ë°°í¬ ê°€ì´ë“œ
- í™˜ê²½ ì„¤ì •
- Docker ì‹¤í–‰
- ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
- SSL ì¸ì¦ì„œ

### 3. ìš´ì˜ ë§¤ë‰´ì–¼
- ì¼ì¼ ì ê²€ ì‚¬í•­
- ë°±ì—… í™•ì¸
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- ì•Œë¦¼ ëŒ€ì‘

### 4. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ
- í•´ê²° ë°©ë²•
- ë¡œê·¸ ë¶„ì„
- ë³µêµ¬ ì ˆì°¨

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¸í”„ë¼
- [ ] Docker ì»¨í…Œì´ë„ˆí™”
- [ ] docker-compose.yml
- [ ] Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ
- [ ] SSL/TLS ì¸ì¦ì„œ
- [ ] ë„ë©”ì¸ ì„¤ì •

### CI/CD
- [ ] GitHub Actions
- [ ] ìë™ í…ŒìŠ¤íŠ¸
- [ ] Docker Hub ì´ë¯¸ì§€
- [ ] ìë™ ë°°í¬

### ëª¨ë‹ˆí„°ë§
- [ ] Prometheus
- [ ] Grafana ëŒ€ì‹œë³´ë“œ
- [ ] ELK Stack
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ

### ë³´ì•ˆ
- [ ] ë³´ì•ˆ í—¤ë”
- [ ] Rate limiting
- [ ] SQL Injection ë°©ì§€
- [ ] XSS ë°©ì§€
- [ ] CSRF ë°©ì§€

### ì„±ëŠ¥
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤
- [ ] Redis ìºì‹±
- [ ] ì»¤ë„¥ì…˜ í’€
- [ ] CDN ì„¤ì •

### ë°±ì—…
- [ ] ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
- [ ] S3 í†µí•©
- [ ] ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
- [ ] Cron ì„¤ì •

### í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] E2E í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸
- [ ] ë³´ì•ˆ ìŠ¤ìº”

### ë¬¸ì„œ
- [ ] API ë¬¸ì„œ
- [ ] ë°°í¬ ê°€ì´ë“œ
- [ ] ìš´ì˜ ë§¤ë‰´ì–¼
- [ ] íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

Week 12 ì™„ë£Œ í›„:
1. **í”„ë¡œë•ì…˜ ë°°í¬** âœ…
2. **ëª¨ë‹ˆí„°ë§ ì‹œì‘** ğŸ“Š
3. **Phase 4 ì™„ë£Œ ë³´ê³ ** ğŸ“
4. **Phase 5 ê³„íš** (ì„ íƒì‚¬í•­)

---

**ë¡œë“œë§µ ì‘ì„± ì™„ë£Œ**  
**ë‹¤ìŒ**: Docker ì»¨í…Œì´ë„ˆí™” ì‹œì‘
