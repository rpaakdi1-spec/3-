# ğŸ¤– ê±°ë˜ì²˜ ìì—°ì–´ ì£¼ë¬¸ ìë™í™” ì‹œìŠ¤í…œ ì„¤ê³„

## ğŸ“‹ ë¬¸ì œ ì •ì˜

### ì…ë ¥ (ê±°ë˜ì²˜ ìš”ì²­)
```
[02/03] ì¶”ê°€ ë°°ì°¨ìš”ì²­
ë°±ì•” _ ì €ì˜¨ â†’ ê²½ì‚° 16íŒ 1ëŒ€

ë™ì´ì²œì„¼í„° â†’ ì–‘ì‚° 16íŒ 1ëŒ€

**2/3(í™”)ëª©ìš°ì´Œ ì˜¤í›„ë°°ì°¨**
15:30 / ìœ¡ê°€ê³µ5í†¤
16:30 / ìœ¡ê°€ê³µ11í†¤
```

### ì¶œë ¥ (êµ¬ì¡°í™”ëœ ì£¼ë¬¸)
```json
{
  "order_date": "2026-02-03",
  "pickup_client": "ë°±ì•”",
  "delivery_client": "ê²½ì‚°",
  "temperature_zone": "REFRIGERATED",
  "pallet_count": 16,
  "vehicle_count": 1
}
```

---

## ğŸ¯ í•´ê²° ë°©ì•ˆ

### ë°©ì•ˆ 1: ê·œì¹™ ê¸°ë°˜ + LLM (GPT-4) - **ê¶Œì¥**

**ì¥ì **: 
- ë¹ ë¥¸ êµ¬í˜„ (1-2ì£¼)
- ë†’ì€ ì •í™•ë„ (95%+)
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
- ìƒˆë¡œìš´ íŒ¨í„´ ì¦‰ì‹œ ëŒ€ì‘

**êµ¬ì¡°**:
```
ìì—°ì–´ ì…ë ¥ 
  â†’ ì „ì²˜ë¦¬ (ë‚ ì§œ, ìˆ«ì ì¶”ì¶œ)
  â†’ LLM (GPT-4) í˜¸ì¶œ
  â†’ í›„ì²˜ë¦¬ (ê²€ì¦, ë§¤ì¹­)
  â†’ êµ¬ì¡°í™”ëœ ì£¼ë¬¸ ìƒì„±
```

**ì˜ˆì‹œ LLM Prompt**:
```
ë‹¹ì‹ ì€ ë¬¼ë¥˜ ì£¼ë¬¸ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê±°ë˜ì²˜ ìš”ì²­ì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ê±°ë˜ì²˜ ë°ì´í„°ë² ì´ìŠ¤:
- ë°±ì•”: {id: 1, address: "ê²½ê¸°ë„ ìš©ì¸ì‹œ ì²˜ì¸êµ¬ ë°±ì•”ë©´", type: "PICKUP"}
- ê²½ì‚°: {id: 5, address: "ê²½ìƒë¶ë„ ê²½ì‚°ì‹œ ì••ëŸ‰ì", type: "DELIVERY"}
- ë™ì´ì²œì„¼í„°: {id: 3, address: "ê²½ê¸°ë„ ì´ì²œì‹œ ë¶€ë°œì ë™ì´ì²œë¡œ", type: "PICKUP"}
- ì–‘ì‚°: {id: 7, address: "ê²½ìƒë‚¨ë„ ì–‘ì‚°ì‹œ ë¬¼ê¸ˆì", type: "DELIVERY"}

ìš”ì²­:
"ë°±ì•” _ ì €ì˜¨ â†’ ê²½ì‚° 16íŒ 1ëŒ€"

ì¶œë ¥ í˜•ì‹:
{
  "pickup_client_id": number,
  "delivery_client_id": number,
  "temperature_zone": "FROZEN" | "REFRIGERATED" | "AMBIENT",
  "pallet_count": number,
  "vehicle_count": number,
  "notes": string
}
```

---

### ë°©ì•ˆ 2: Few-shot Learning + Fine-tuned Model

**ì¥ì **:
- ë” ì •í™•í•œ íŠ¹í™” ëª¨ë¸
- ë¹„ìš© ì ˆê° (ì¥ê¸°ì )
- íšŒì‚¬ íŠ¹í™” íŒ¨í„´ í•™ìŠµ

**êµ¬ì¡°**:
```
í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ (100-500ê±´)
  â†’ GPT-4 fine-tuning
  â†’ ëª¨ë¸ ë°°í¬
  â†’ ì‹¤ì‹œê°„ ì¶”ë¡ 
```

**í•„ìš” ë°ì´í„°**:
```json
[
  {
    "input": "ë°±ì•” _ ì €ì˜¨ â†’ ê²½ì‚° 16íŒ 1ëŒ€",
    "output": {
      "pickup_client_id": 1,
      "delivery_client_id": 5,
      "temperature_zone": "REFRIGERATED",
      "pallet_count": 16
    }
  },
  {
    "input": "2/3(í™”)ëª©ìš°ì´Œ ì˜¤í›„ë°°ì°¨ 15:30 / ìœ¡ê°€ê³µ5í†¤",
    "output": {
      "pickup_client_id": 8,
      "delivery_client_id": null,
      "pickup_time": "15:30",
      "vehicle_type": "5TON"
    }
  }
]
```

---

### ë°©ì•ˆ 3: Hybrid (ê·œì¹™ + LLM + í•™ìŠµ)

**ì¥ì **:
- ìµœê³  ì •í™•ë„
- ì ì§„ì  ê°œì„ 
- ì‚¬ëŒ ê²€ì¦ ìµœì†Œí™”

**êµ¬ì¡°**:
```
1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ ì „ì²˜ë¦¬
  - ë‚ ì§œ ì¶”ì¶œ: "02/03", "2/3(í™”)" â†’ 2026-02-03
  - ìˆ«ì ì¶”ì¶œ: "16íŒ" â†’ 16, "5í†¤" â†’ 5000kg
  - ì˜¨ë„ í‚¤ì›Œë“œ: "ì €ì˜¨", "ëƒ‰ë™", "ëƒ‰ì¥", "ìƒì˜¨"

2ë‹¨ê³„: ê±°ë˜ì²˜ ë§¤ì¹­ (Fuzzy + Vector DB)
  - "ë°±ì•”" â†’ DB ê²€ìƒ‰ â†’ id: 1
  - "ê²½ì‚°" â†’ DB ê²€ìƒ‰ â†’ id: 5
  - Levenshtein distance < 2
  - ë˜ëŠ” Vector embedding ìœ ì‚¬ë„ > 0.85

3ë‹¨ê³„: LLM ë³´ì™„
  - ì• ë§¤í•œ ê²½ìš°ë§Œ LLM í˜¸ì¶œ
  - ìƒˆë¡œìš´ ê±°ë˜ì²˜ëª… ì¶”ë¡ 
  - ì˜¨ë„ëŒ€ ì¶”ë¡ 

4ë‹¨ê³„: ì‚¬ìš©ì ê²€ì¦
  - ì‹ ë¢°ë„ < 80% â†’ ì‚¬ìš©ì í™•ì¸
  - í™•ì¸ëœ ë°ì´í„° â†’ í›ˆë ¨ DB ì¶”ê°€

5ë‹¨ê³„: ì§€ì† í•™ìŠµ
  - ì›” 1íšŒ ëª¨ë¸ ì¬í•™ìŠµ
  - ìƒˆë¡œìš´ íŒ¨í„´ ë°˜ì˜
```

---

## ğŸ’» êµ¬í˜„ ë°©ì•ˆ (ë°©ì•ˆ 1 ê¸°ì¤€)

### 1. ë°±ì—”ë“œ API êµ¬ì¡°

```python
# backend/app/services/order_nlp_service.py
from openai import OpenAI
import re
from datetime import datetime
from typing import Dict, List, Optional

class OrderNLPService:
    def __init__(self, db: Session):
        self.db = db
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def parse_order_request(self, text: str) -> List[Dict]:
        """ìì—°ì–´ ì£¼ë¬¸ ìš”ì²­ì„ íŒŒì‹±"""
        
        # 1. ì „ì²˜ë¦¬
        preprocessed = self._preprocess(text)
        
        # 2. ê±°ë˜ì²˜ DB ê°€ì ¸ì˜¤ê¸°
        clients = self._get_clients_context()
        
        # 3. LLM í˜¸ì¶œ
        parsed_orders = await self._call_llm(preprocessed, clients)
        
        # 4. í›„ì²˜ë¦¬ ë° ê²€ì¦
        validated_orders = self._validate_and_enrich(parsed_orders)
        
        return validated_orders
    
    def _preprocess(self, text: str) -> str:
        """ì „ì²˜ë¦¬: ë‚ ì§œ, íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”"""
        # ë‚ ì§œ ì¶”ì¶œ
        date_pattern = r'(\d{1,2})/(\d{1,2})'
        text = re.sub(date_pattern, lambda m: f"2026-{m.group(1).zfill(2)}-{m.group(2).zfill(2)}", text)
        
        # ì˜¨ë„ í‚¤ì›Œë“œ ì •ê·œí™”
        temp_map = {
            'ì €ì˜¨': 'REFRIGERATED',
            'ëƒ‰ì¥': 'REFRIGERATED',
            'ëƒ‰ë™': 'FROZEN',
            'ìƒì˜¨': 'AMBIENT'
        }
        for key, value in temp_map.items():
            text = text.replace(key, f"[{value}]")
        
        return text
    
    def _get_clients_context(self) -> str:
        """ê±°ë˜ì²˜ DBë¥¼ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜"""
        clients = self.db.query(Client).filter(Client.is_active == True).all()
        
        context = "ê±°ë˜ì²˜ ë°ì´í„°ë² ì´ìŠ¤:\n"
        for client in clients:
            context += f"- {client.name} (ì½”ë“œ: {client.code}, ì£¼ì†Œ: {client.address}, íƒ€ì…: {client.client_type})\n"
        
        return context
    
    async def _call_llm(self, text: str, clients_context: str) -> List[Dict]:
        """LLM í˜¸ì¶œ"""
        prompt = f"""ë‹¹ì‹ ì€ ë¬¼ë¥˜ ì£¼ë¬¸ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ê±°ë˜ì²˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ì£¼ë¬¸ ì •ë³´ë¡œ ë³€í™˜í•˜ì„¸ìš”.

{clients_context}

ê·œì¹™:
1. ë‚ ì§œëŠ” YYYY-MM-DD í˜•ì‹
2. ì˜¨ë„ëŒ€ëŠ” FROZEN, REFRIGERATED, AMBIENT ì¤‘ í•˜ë‚˜
3. ê±°ë˜ì²˜ëª…ì€ ìœ„ DBì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ ë§¤ì¹­
4. "íŒ"ì€ pallet_count, "í†¤"ì€ weight_kgë¡œ ë³€í™˜
5. í™”ì‚´í‘œ(â†’) ë˜ëŠ” "ì—ì„œ~ë¡œ" íŒ¨í„´ìœ¼ë¡œ ìƒì°¨ì§€/í•˜ì°¨ì§€ êµ¬ë¶„

ìš”ì²­:
{text}

ì¶œë ¥ í˜•ì‹ (JSON Array):
[
  {{
    "order_date": "YYYY-MM-DD",
    "pickup_client_name": "ê±°ë˜ì²˜ëª…",
    "delivery_client_name": "ê±°ë˜ì²˜ëª…",
    "temperature_zone": "FROZEN|REFRIGERATED|AMBIENT",
    "pallet_count": number,
    "weight_kg": number or null,
    "pickup_time": "HH:MM" or null,
    "notes": "ì¶”ê°€ ì •ë³´",
    "confidence": 0.0-1.0
  }}
]
"""
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",  # ë¹ ë¥´ê³  ì €ë ´
            messages=[
                {"role": "system", "content": "You are a logistics order processing expert."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ì¼ê´€ì„± ìš°ì„ 
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content
        return json.loads(result)
    
    def _validate_and_enrich(self, orders: List[Dict]) -> List[Dict]:
        """ê²€ì¦ ë° DB ë§¤ì¹­"""
        validated = []
        
        for order in orders:
            # ê±°ë˜ì²˜ ë§¤ì¹­
            pickup_client = self._match_client(order['pickup_client_name'])
            delivery_client = self._match_client(order['delivery_client_name'])
            
            if pickup_client:
                order['pickup_client_id'] = pickup_client.id
                order['pickup_address'] = pickup_client.address
            
            if delivery_client:
                order['delivery_client_id'] = delivery_client.id
                order['delivery_address'] = delivery_client.address
            
            # ì‹ ë¢°ë„ ì²´í¬
            if order.get('confidence', 0) < 0.7:
                order['needs_review'] = True
            
            validated.append(order)
        
        return validated
    
    def _match_client(self, client_name: str) -> Optional[Client]:
        """ê±°ë˜ì²˜ëª… ë§¤ì¹­ (Fuzzy)"""
        from fuzzywuzzy import fuzz
        
        clients = self.db.query(Client).filter(Client.is_active == True).all()
        
        best_match = None
        best_score = 0
        
        for client in clients:
            score = fuzz.ratio(client_name, client.name)
            if score > best_score:
                best_score = score
                best_match = client
        
        # 80% ì´ìƒ ìœ ì‚¬ë„ë§Œ ë§¤ì¹­
        if best_score >= 80:
            return best_match
        
        return None
```

### 2. API ì—”ë“œí¬ì¸íŠ¸

```python
# backend/app/api/orders.py
@router.post("/parse-nlp")
async def parse_order_nlp(
    request: dict,
    db: Session = Depends(get_db)
):
    """ìì—°ì–´ ì£¼ë¬¸ íŒŒì‹±"""
    text = request.get('text', '')
    
    if not text:
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    
    nlp_service = OrderNLPService(db)
    parsed_orders = await nlp_service.parse_order_request(text)
    
    return {
        "success": True,
        "orders": parsed_orders,
        "count": len(parsed_orders)
    }
```

### 3. í”„ë¡ íŠ¸ì—”ë“œ UI

```tsx
// frontend/src/components/orders/OrderNLPInput.tsx
function OrderNLPInput() {
  const [text, setText] = useState('')
  const [loading, setLoading] = useState(false)
  const [parsedOrders, setParsedOrders] = useState([])

  const handleParse = async () => {
    setLoading(true)
    try {
      const response = await ordersAPI.parseNLP({ text })
      setParsedOrders(response.data.orders)
    } catch (err) {
      alert('íŒŒì‹± ì‹¤íŒ¨')
    } finally {
      setLoading(false)
    }
  }

  return (
    <div className="card">
      <h3>ğŸ“ ìì—°ì–´ ì£¼ë¬¸ ì…ë ¥</h3>
      
      <textarea
        value={text}
        onChange={(e) => setText(e.target.value)}
        placeholder="ì˜ˆ: [02/03] ì¶”ê°€ ë°°ì°¨ìš”ì²­&#10;ë°±ì•” _ ì €ì˜¨ â†’ ê²½ì‚° 16íŒ 1ëŒ€"
        rows={8}
        style={{ width: '100%', padding: '12px', fontSize: '14px' }}
      />
      
      <button 
        onClick={handleParse}
        disabled={loading || !text}
        className="button"
      >
        {loading ? 'ğŸ¤– ë¶„ì„ ì¤‘...' : 'ğŸ¤– AI íŒŒì‹±'}
      </button>

      {parsedOrders.length > 0 && (
        <div style={{ marginTop: '20px' }}>
          <h4>íŒŒì‹± ê²°ê³¼ ({parsedOrders.length}ê±´)</h4>
          {parsedOrders.map((order, idx) => (
            <div key={idx} style={{ 
              padding: '12px', 
              border: '1px solid #ddd', 
              borderRadius: '4px',
              marginBottom: '10px',
              backgroundColor: order.needs_review ? '#fff3cd' : '#d4edda'
            }}>
              <div><strong>ì£¼ë¬¸ {idx + 1}</strong></div>
              <div>ìƒì°¨: {order.pickup_client_name}</div>
              <div>í•˜ì°¨: {order.delivery_client_name}</div>
              <div>ì˜¨ë„: {order.temperature_zone}</div>
              <div>íŒ”ë ˆíŠ¸: {order.pallet_count}ê°œ</div>
              {order.needs_review && (
                <div style={{ color: '#856404', marginTop: '8px' }}>
                  âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ - í™•ì¸ í•„ìš”
                </div>
              )}
              <button 
                onClick={() => handleCreateOrder(order)}
                className="button secondary"
                style={{ marginTop: '8px' }}
              >
                âœ“ ì£¼ë¬¸ ìƒì„±
              </button>
            </div>
          ))}
        </div>
      )}
    </div>
  )
}
```

---

## ğŸ“Š ì„±ëŠ¥ ë° ë¹„ìš©

### LLM í˜¸ì¶œ ë¹„ìš© (GPT-4o-mini)
- Input: $0.150 / 1M tokens
- Output: $0.600 / 1M tokens
- ì£¼ë¬¸ 1ê±´ë‹¹ ì•½ 500 tokens (ì…ë ¥ 400 + ì¶œë ¥ 100)
- **ë¹„ìš©: ì•½ $0.0003 (0.4ì›) per ì£¼ë¬¸**

### ì˜ˆìƒ ì •í™•ë„
- 1ë‹¨ê³„ (ê·œì¹™ ê¸°ë°˜): 60-70%
- 2ë‹¨ê³„ (Fuzzy ë§¤ì¹­): 80-85%
- 3ë‹¨ê³„ (LLM): 95-98%
- **ì „ì²´: 95%+ ì •í™•ë„**

### ì²˜ë¦¬ ì†ë„
- ì „ì²˜ë¦¬: 10ms
- Fuzzy ë§¤ì¹­: 50ms
- LLM í˜¸ì¶œ: 1-2ì´ˆ
- **ì „ì²´: ì•½ 2ì´ˆ per ìš”ì²­**

---

## ğŸ¯ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: MVP (1-2ì£¼)
1. âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ êµ¬í˜„
2. âœ… LLM í†µí•© (GPT-4o-mini)
3. âœ… ê¸°ë³¸ UI (í…ìŠ¤íŠ¸ ì…ë ¥ â†’ íŒŒì‹±)
4. âœ… ê±°ë˜ì²˜ Fuzzy ë§¤ì¹­

### Phase 2: ê°œì„  (2-3ì£¼)
1. âœ… ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ê°€
2. âœ… ì‚¬ìš©ì ê²€ì¦ UI
3. âœ… ê²€ì¦ëœ ë°ì´í„° í•™ìŠµ DB ì €ì¥
4. âœ… ë°°ì¹˜ ì²˜ë¦¬ (ì—¬ëŸ¬ ì£¼ë¬¸ ë™ì‹œ íŒŒì‹±)

### Phase 3: ê³ ë„í™” (1-2ê°œì›”)
1. âœ… Fine-tuned ëª¨ë¸ í›ˆë ¨
2. âœ… Vector DB í†µí•© (ê±°ë˜ì²˜ ê²€ìƒ‰)
3. âœ… ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸
4. âœ… ëŒ€ì‹œë³´ë“œ (íŒŒì‹± ì„±ê³µë¥ , ì˜¤ë¥˜ìœ¨)

---

## ğŸš€ ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜

```bash
# 1. OpenAI API í‚¤ ì„¤ì •
export OPENAI_API_KEY="sk-..."

# 2. í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai fuzzywuzzy python-Levenshtein

# 3. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python test_order_nlp.py
```

---

## ğŸ’¡ ê¶Œì¥ ì‚¬í•­

1. **ë°©ì•ˆ 1 (ê·œì¹™ + LLM)ë¡œ ì‹œì‘** â† ê°€ì¥ ë¹ ë¥´ê³  íš¨ê³¼ì 
2. 100-200ê±´ ë°ì´í„° ìˆ˜ì§‘ í›„ **Fine-tuning ê³ ë ¤**
3. ì‚¬ìš©ì í”¼ë“œë°± ë£¨í”„ êµ¬ì¶•
4. ì›” 1íšŒ ì„±ëŠ¥ ë¦¬ë·° ë° ëª¨ë¸ ì—…ë°ì´íŠ¸

---

**ì§ˆë¬¸ì´ë‚˜ ì¶”ê°€ ìš”êµ¬ì‚¬í•­ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!** ğŸš€
